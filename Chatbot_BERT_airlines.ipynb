{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mIlUoxEg0Gb",
        "outputId": "4b640637-e6e4-4108-cbe0-dfe95bae67d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zWt8WDReM--"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChbTsF9vnYYI",
        "outputId": "fc44d2a3-54c8-43c8-f303-85743155f9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/Nurul&Nabil(thesis)/Ner_dataset'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVkwiKFqq9Ne",
        "outputId": "14bed18a-51dc-4511-e1ce-8fdaaeebf92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " annotated_dataset_2.csv    atis_intents.csv\t  flagged\n",
            "'atis_intents (1).gsheet'   atis_intents.gsheet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Nurul&Nabil(thesis)/Ner_dataset\")"
      ],
      "metadata": {
        "id": "JnJfCEUPoNGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "IGN7BTEQxyly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5f9cccca-c89d-49f1-8ef8-9e5642c1264e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data={\"intents\":[{\n",
        "\t\t\"tag\": \"atis_flight\",\n",
        "\t\t\"responses\": [\"Yes,flight is available\",\"No,flight isn't available\",\"Departure: 23:00  -  Arrival:  8:30\",\"Departure : 1:40\",\"Arrival: 5:30\"]\n",
        "\t},{\n",
        "\t\t\"tag\": \"atis_flight_time\",\n",
        "\t\t\"responses\": [\" Departure: 8:00  -  Arrival: 20:00\",\"Departure: 10:00\",\"Arrival: 16:00\"]\n",
        "\t},{\n",
        "\t\t\"tag\": \"atis_airfare\",\n",
        "\t\t\"responses\": [ \" 560$ \", \"690$\", \"710$\", \"1200$\"]\n",
        "\t},{\n",
        "\t\t\"tag\": \"atis_airport\",\n",
        "\t\t\"responses\": [\"Hartsfield–Jackson Atlanta International Airport\",\"Dallas/Fort Worth International Airport\",\"Denver International Airport\",\"Los Angeles International Airport\"]\n",
        "\t},{\n",
        "\t\t\"tag\": \"atis_ground_service\",\n",
        "\t\t\"responses\": [\"Airport Limousine Service Sedan (4 passenger) - $45 and up, SUV (6 passenger) - $53 and up, Stretch Limousine (6 passenger) - $55 and up, (702) 888-4848 or (888) 696-4400\"]\n",
        "\t},{\n",
        "\t\t\"tag\": \"atis_aircraft\",\n",
        "\t\t\"responses\": [\"F/A-18A Hornet\",\"F-35B Lightning II\",\"UC-12W Huron\",\"C-2A Greyhound\",\" Airbus A380\"]\n",
        "\t},{\n",
        "      \"tag\":\"atis_airline\",\n",
        "      \"responses\": [\"American Airlines\",\"Avelo Airlines\",\"Breeze Airways\",\"Delta Air Lines\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_abbreviation\",\n",
        "      \"responses\": [\"A - First Class Discounted\",\"B - Economy/Coach – Usually an upgradable fare to Business\",\"C - Business Class\",\"D - Business Class Discounted\",\"E - Shuttle Service (no reservation allowed) or Economy/Coach Discounted\",\n",
        "                     \"F - First Class\",\"G - Conditional Reservation\",\"H - Economy/Coach Discounted\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_flight_no\",\n",
        "      \"responses\": [\"2490\",\"2491\",\"2492\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_quantity\",\n",
        "     \"responses\":[\"4 different classes \",\"5 classes\"]\n",
        "\n",
        "  },{\n",
        "      \"tag\":\"atis_city\",\n",
        "      \"responses\":[\"Appleton, WI (ATW)\",\"Atlanta, GA (ATL)\",\"Boston, MA (BOS)\",\"Cleveland, OH (CLE)\",\"Columbus, OH (CMH)\",\"Dallas/Fort Worth, TX (DFW)\",\"Denver, CO (DEN)\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_capacity\",\n",
        "     \"responses\":[\"100 passengers\",\"200 passengers\",\"50 passengers\",\"500 passengers\",\"1000 passengers\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_distance\",\n",
        "      \"responses\":[\"13 min (12.2 mi) via US-101 S\",\"8 min (2.6 mi) via Las Vegas Blvd S and E Tropicana Ave\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_ground_fare\",\n",
        "     \"responses\":[\"Full-size SUV : $30/day\", \"Mini :\t$50/day\",\"Premium  :\t$27/day\",\"Passenger van\t$89/day\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_airport\",\n",
        "     \"responses\":[\"airports in New York\",\"Birmingham\",\"Huntsville\",\"Dothan\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_meal\",\n",
        "     \"responses\":[\"yes,a meal is available\",\"No,there is no meal available\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_restriction\",\n",
        "      \"responses\":[\"some restriction\"]\n",
        "  },{\n",
        "      \"tag\":\"atis_cheapest\",\n",
        "     \"responses\":[\"200$-300$\"]\n",
        "  }\n",
        "]}"
      ],
      "metadata": {
        "id": "jCg-MkmXF-S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"atis_intents.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "W7nxoPmwySeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0e2d6263-f491-4a01-eab1-7244cfee07e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           atis_flight  \\\n",
              "0          atis_flight   \n",
              "1     atis_flight_time   \n",
              "2         atis_airfare   \n",
              "3         atis_airfare   \n",
              "4          atis_flight   \n",
              "...                ...   \n",
              "4972      atis_airfare   \n",
              "4973       atis_flight   \n",
              "4974      atis_airline   \n",
              "4975       atis_flight   \n",
              "4976       atis_flight   \n",
              "\n",
              "      i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  \n",
              "0      what flights are available from pittsburgh to...                                \n",
              "1      what is the arrival time in san francisco for...                                \n",
              "2               cheapest airfare from tacoma to orlando                                \n",
              "3      round trip fares from pittsburgh to philadelp...                                \n",
              "4      i need a flight tomorrow from columbus to min...                                \n",
              "...                                                 ...                                \n",
              "4972   what is the airfare for flights from denver t...                                \n",
              "4973   do you have any flights from denver to baltim...                                \n",
              "4974          which airlines fly into and out of denver                                \n",
              "4975   does continental fly from boston to san franc...                                \n",
              "4976   is there a delta flight from denver to san fr...                                \n",
              "\n",
              "[4977 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8a9b8ac-03e8-4558-8095-99578c043209\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>atis_flight</th>\n",
              "      <th>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i need a flight tomorrow from columbus to min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4972</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>what is the airfare for flights from denver t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4973</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>do you have any flights from denver to baltim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>atis_airline</td>\n",
              "      <td>which airlines fly into and out of denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>does continental fly from boston to san franc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>is there a delta flight from denver to san fr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4977 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8a9b8ac-03e8-4558-8095-99578c043209')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8a9b8ac-03e8-4558-8095-99578c043209 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8a9b8ac-03e8-4558-8095-99578c043209');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=['label','text']\n",
        "df"
      ],
      "metadata": {
        "id": "BKqXqyE1yh8B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f8334d9d-d90d-47cd-8b8b-f1d3ecaf882a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 label                                               text\n",
              "0          atis_flight   what flights are available from pittsburgh to...\n",
              "1     atis_flight_time   what is the arrival time in san francisco for...\n",
              "2         atis_airfare            cheapest airfare from tacoma to orlando\n",
              "3         atis_airfare   round trip fares from pittsburgh to philadelp...\n",
              "4          atis_flight   i need a flight tomorrow from columbus to min...\n",
              "...                ...                                                ...\n",
              "4972      atis_airfare   what is the airfare for flights from denver t...\n",
              "4973       atis_flight   do you have any flights from denver to baltim...\n",
              "4974      atis_airline          which airlines fly into and out of denver\n",
              "4975       atis_flight   does continental fly from boston to san franc...\n",
              "4976       atis_flight   is there a delta flight from denver to san fr...\n",
              "\n",
              "[4977 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8582fa24-5ac1-4776-88be-7726f136286e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i need a flight tomorrow from columbus to min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4972</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>what is the airfare for flights from denver t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4973</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>do you have any flights from denver to baltim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>atis_airline</td>\n",
              "      <td>which airlines fly into and out of denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>does continental fly from boston to san franc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>is there a delta flight from denver to san fr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4977 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8582fa24-5ac1-4776-88be-7726f136286e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8582fa24-5ac1-4776-88be-7726f136286e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8582fa24-5ac1-4776-88be-7726f136286e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "Z_3AF5ZAyooi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc74008f-45bb-40db-f743-d13d85850c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "atis_flight                                 3665\n",
              "atis_airfare                                 423\n",
              "atis_ground_service                          255\n",
              "atis_airline                                 157\n",
              "atis_abbreviation                            147\n",
              "atis_aircraft                                 81\n",
              "atis_flight_time                              54\n",
              "atis_quantity                                 51\n",
              "atis_flight#atis_airfare                      21\n",
              "atis_airport                                  20\n",
              "atis_distance                                 20\n",
              "atis_city                                     19\n",
              "atis_ground_fare                              18\n",
              "atis_capacity                                 16\n",
              "atis_flight_no                                12\n",
              "atis_meal                                      6\n",
              "atis_restriction                               6\n",
              "atis_airline#atis_flight_no                    2\n",
              "atis_ground_service#atis_ground_fare           1\n",
              "atis_airfare#atis_flight_time                  1\n",
              "atis_cheapest                                  1\n",
              "atis_aircraft#atis_flight#atis_flight_no       1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the labels into encodings\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])\n",
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "id": "Si-lwOEVyyjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a4459d-f9d0-40fb-bdaa-7238be5a946d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12    0.736387\n",
              "3     0.084991\n",
              "17    0.051236\n",
              "5     0.031545\n",
              "0     0.029536\n",
              "1     0.016275\n",
              "15    0.010850\n",
              "20    0.010247\n",
              "13    0.004219\n",
              "7     0.004018\n",
              "11    0.004018\n",
              "10    0.003818\n",
              "16    0.003617\n",
              "8     0.003215\n",
              "14    0.002411\n",
              "19    0.001206\n",
              "21    0.001206\n",
              "6     0.000402\n",
              "18    0.000201\n",
              "4     0.000201\n",
              "9     0.000201\n",
              "2     0.000201\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example we have used all the utterances for training purpose\n",
        "train_text, train_labels = df['text'], df['label']"
      ],
      "metadata": {
        "id": "D2iB2eAx15Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD0xwigFs2_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b4f6c1-02a1-4d44-c099-9e3d8c548bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "# Load the DistilBert tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "# Import the DistilBert pretrained model\n",
        "bert = DistilBertModel.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"this is a distil bert model.\",\"data is oil\"]\n",
        "# Encode the text\n",
        "encoded_input = tokenizer('text', padding=True,truncation=True, return_tensors='pt')\n",
        "print(encoded_input)\n",
        "'''In input_ids:\n",
        "101 - Indicates beginning of the sentence\n",
        "102 - Indicates end of the sentence\n",
        "In attention_mask:\n",
        "1 - Actual token\n",
        "0 - Padded token'''"
      ],
      "metadata": {
        "id": "HuFNamL7ekSA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3421af55-5fda-4481-8d28-4129a3a23ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 3793,  102]]), 'attention_mask': tensor([[1, 1, 1]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In input_ids:\\n101 - Indicates beginning of the sentence\\n102 - Indicates end of the sentence\\nIn attention_mask:\\n1 - Actual token\\n0 - Padded token'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "pd.Series(seq_len).hist(bins = 10)\n",
        "# Based on the histogram we are selecting the max len as 16\n",
        "max_seq_len = 16"
      ],
      "metadata": {
        "id": "N1mwcob93NGE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "494afeab-78ce-40aa-f74f-af1612e18191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "_dq1crhu34iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa80511e-2499-4e4f-9b93-5d4fac3ddb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "print(len(train_mask))"
      ],
      "metadata": {
        "id": "Bv__LWKb4S-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863e1d4d-b4be-417d-c689-c994c4a14825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#define a batch size\n",
        "batch_size = 64\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# DataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "print(len(train_dataloader))\n",
        "print(train_data)"
      ],
      "metadata": {
        "id": "_gt2KCNT4dq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74008eb5-15c1-4465-a8bc-6f175485e410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n",
            "<torch.utils.data.dataset.TensorDataset object at 0x7f34fb2db5e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "   def __init__(self, bert):      \n",
        "       super(BERT_Arch, self).__init__()\n",
        "       self.bert = bert \n",
        "      \n",
        "       # dropout layer\n",
        "       self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "       # relu activation function\n",
        "       self.relu =  nn.ReLU()\n",
        "       # dense layer\n",
        "       self.fc1 = nn.Linear(768,3072)\n",
        "       self.fc2 = nn.Linear(3072,768)\n",
        "       self.fc3 = nn.Linear(768,22)\n",
        "       #softmax activation function\n",
        "       self.softmax = nn.LogSoftmax(dim=1)\n",
        "       #define the forward pass\n",
        "   def forward(self, sent_id, mask):\n",
        "      #pass the inputs to the model  \n",
        "      cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      \n",
        "      x = self.fc2(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      # output layer\n",
        "      x = self.fc3(x)\n",
        "   \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "dhDDZ0Li4gFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAQjy9a9r8xG",
        "outputId": "82bd4f81-30d8-4ddc-bf60-37bcab7d5f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
        "for param in bert.parameters():\n",
        "      param.requires_grad = False\n",
        "model = BERT_Arch(bert)\n",
        "# push the model to GPU\n",
        "model = model.to(device)\n",
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "0Qy0SPOc4sSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4b7d06-8a8e-4c03-e021-112ba5426b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "BERT_Arch                                               --\n",
              "├─DistilBertModel: 1-1                                  --\n",
              "│    └─Embeddings: 2-1                                  --\n",
              "│    │    └─Embedding: 3-1                              (23,440,896)\n",
              "│    │    └─Embedding: 3-2                              (393,216)\n",
              "│    │    └─LayerNorm: 3-3                              (1,536)\n",
              "│    │    └─Dropout: 3-4                                --\n",
              "│    └─Transformer: 2-2                                 --\n",
              "│    │    └─ModuleList: 3-5                             (42,527,232)\n",
              "├─Dropout: 1-2                                          --\n",
              "├─ReLU: 1-3                                             --\n",
              "├─Linear: 1-4                                           2,362,368\n",
              "├─Linear: 1-5                                           2,360,064\n",
              "├─Linear: 1-6                                           16,918\n",
              "├─LogSoftmax: 1-7                                       --\n",
              "================================================================================\n",
              "Total params: 71,102,230\n",
              "Trainable params: 4,739,350\n",
              "Non-trainable params: 66,362,880\n",
              "================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "9d8FQ82w6woK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db16a073-430d-4161-8f99-726ba8c234af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight='balanced',classes= np.unique(train_labels),y= train_labels)\n",
        "print(len(class_wts))"
      ],
      "metadata": {
        "id": "RasIlm0p7oSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc01d0aa-a3a6-4818-d4e7-e83d8c2ca846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "# loss function\n",
        "cross_entropy = nn.NLLLoss(weight=weights) "
      ],
      "metadata": {
        "id": "uZdJWRQ-7odY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "# number of training epochs\n",
        "epochs = 2\n",
        "# We can also use learning rate scheduler to achieve better results\n",
        "lr_sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
      ],
      "metadata": {
        "id": "AgnJPAHg8o4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "  tot_loss = 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 1000 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step,    len(train_dataloader)))\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch] \n",
        "    sent_id, mask, labels = batch\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "    print(preds)\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "   \n",
        "    # add on to the total loss\n",
        "    tot_loss = tot_loss + loss.item()\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "    # clip the the gradients to 1.0. It helps in preventing the    exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # clear calculated gradients\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    # We are not using learning rate scheduler as of now\n",
        "    # lr_sch.step()\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = tot_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds\n",
        "  \n"
      ],
      "metadata": {
        "id": "_-e8VQ4_-dms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "id": "kY430WZjBKkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e180d4-f01a-4405-bce4-a77e4f4b2bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 2\n",
            "tensor([[-3.0760, -3.1656, -3.0583,  ..., -3.1207, -3.0178, -3.0575],\n",
            "        [-3.0498, -3.1370, -3.0683,  ..., -3.1113, -3.0552, -3.0945],\n",
            "        [-3.0664, -3.1011, -3.0550,  ..., -3.0855, -3.0509, -3.0917],\n",
            "        ...,\n",
            "        [-3.0755, -3.1656, -3.0822,  ..., -3.0518, -3.0221, -3.1181],\n",
            "        [-3.0478, -3.1837, -3.0783,  ..., -3.1489, -3.0038, -3.1343],\n",
            "        [-3.0238, -3.1207, -3.0616,  ..., -3.1335, -3.0231, -3.1150]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.5165, -2.7828, -3.2488,  ..., -3.4280, -2.4914, -3.4314],\n",
            "        [-2.5379, -2.8524, -3.3149,  ..., -3.5444, -2.5458, -3.4276],\n",
            "        [-2.5123, -2.7980, -3.2593,  ..., -3.4214, -2.5445, -3.4304],\n",
            "        ...,\n",
            "        [-2.5170, -2.6257, -3.3905,  ..., -3.5239, -2.4503, -3.4180],\n",
            "        [-2.5134, -2.8554, -3.3475,  ..., -3.4921, -2.4646, -3.4073],\n",
            "        [-2.5490, -2.8110, -3.3444,  ..., -3.4494, -2.4647, -3.4321]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.4322, -2.1429, -3.8915,  ..., -4.1054, -2.7292, -4.0618],\n",
            "        [-2.6766, -2.1048, -3.6811,  ..., -4.0835, -2.8339, -3.9347],\n",
            "        [-2.6485, -2.0308, -3.7093,  ..., -4.0750, -2.6487, -3.9111],\n",
            "        ...,\n",
            "        [-2.6007, -1.9602, -3.8093,  ..., -4.0813, -2.7856, -3.9538],\n",
            "        [-2.5704, -2.0400, -3.8023,  ..., -4.1296, -2.7079, -3.9860],\n",
            "        [-2.5952, -2.2494, -3.8453,  ..., -4.1437, -2.6897, -3.9890]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.4458, -2.0171, -4.1159,  ..., -4.4489, -2.6522, -4.2340],\n",
            "        [-2.7083, -1.7334, -4.3657,  ..., -4.6426, -2.6449, -4.4887],\n",
            "        [-2.8077, -1.8705, -4.3096,  ..., -4.7454, -2.5359, -4.4116],\n",
            "        ...,\n",
            "        [-2.6856, -1.8124, -4.5480,  ..., -4.9246, -2.6272, -4.6335],\n",
            "        [-2.6353, -1.9260, -4.3231,  ..., -4.5578, -2.5908, -4.3881],\n",
            "        [-2.7145, -1.8154, -4.1787,  ..., -4.5819, -2.6558, -4.3008]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8534, -2.0142, -4.5412,  ..., -4.8637, -2.3335, -4.7707],\n",
            "        [-3.0340, -1.8186, -4.6355,  ..., -4.8440, -2.3161, -4.8462],\n",
            "        [-2.9956, -1.8862, -4.6166,  ..., -4.7226, -2.4737, -4.5831],\n",
            "        ...,\n",
            "        [-3.1375, -1.8833, -4.6211,  ..., -5.1564, -2.3817, -4.9337],\n",
            "        [-2.8710, -1.9424, -4.5324,  ..., -4.9832, -2.4434, -4.6850],\n",
            "        [-3.0135, -1.9481, -4.3567,  ..., -4.9290, -2.5770, -4.6829]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.3410, -1.9131, -4.6359,  ..., -5.1627, -2.3235, -4.9285],\n",
            "        [-2.8702, -2.3321, -4.7427,  ..., -5.1060, -2.4485, -5.0132],\n",
            "        [-3.4347, -2.0626, -5.0970,  ..., -5.5801, -2.2002, -5.4017],\n",
            "        ...,\n",
            "        [-3.3069, -2.0224, -4.9131,  ..., -5.3047, -2.3368, -5.1506],\n",
            "        [-3.3285, -2.0075, -4.7468,  ..., -4.9688, -2.4723, -4.8758],\n",
            "        [-3.2736, -2.3003, -4.6503,  ..., -4.8337, -2.5791, -4.8316]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.7916, -2.3033, -5.0272,  ..., -5.0447, -2.2787, -4.9990],\n",
            "        [-3.2743, -2.1657, -5.1177,  ..., -5.2842, -2.2109, -5.3601],\n",
            "        [-3.0675, -2.4241, -5.0780,  ..., -5.5363, -2.1507, -5.2137],\n",
            "        ...,\n",
            "        [-3.3372, -2.1632, -5.5652,  ..., -5.9452, -2.0574, -5.7094],\n",
            "        [-2.9150, -2.2461, -5.0290,  ..., -5.2083, -2.2192, -5.3157],\n",
            "        [-3.2627, -2.0675, -5.0015,  ..., -5.6486, -2.0907, -5.5224]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.1936, -2.4210, -5.2155,  ..., -5.3568, -2.0233, -5.2424],\n",
            "        [-3.0462, -2.5228, -4.9962,  ..., -5.2694, -2.0556, -5.2868],\n",
            "        [-3.3566, -2.5550, -5.2328,  ..., -5.6506, -1.9973, -5.7492],\n",
            "        ...,\n",
            "        [-2.8057, -2.4341, -4.5129,  ..., -4.8105, -2.2803, -4.8491],\n",
            "        [-3.5043, -2.6045, -5.4436,  ..., -5.8783, -2.1258, -5.7421],\n",
            "        [-3.3892, -2.4672, -5.7697,  ..., -5.8049, -1.8750, -5.7914]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.1500, -2.8715, -4.7036,  ..., -4.8845, -2.3393, -4.6891],\n",
            "        [-3.2873, -2.7831, -5.2882,  ..., -5.6723, -2.1242, -5.1230],\n",
            "        [-3.2666, -2.8155, -5.2470,  ..., -5.4449, -2.3338, -5.0224],\n",
            "        ...,\n",
            "        [-3.3156, -2.6901, -5.3262,  ..., -5.3104, -2.4100, -4.9189],\n",
            "        [-3.0079, -2.7755, -5.1566,  ..., -5.3306, -2.1552, -4.8418],\n",
            "        [-3.2497, -2.6406, -5.2033,  ..., -5.1792, -2.1575, -4.8050]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.1095, -2.8416, -4.8551,  ..., -5.0290, -2.2966, -4.0875],\n",
            "        [-2.9134, -2.7844, -4.6540,  ..., -4.7251, -2.5504, -4.0948],\n",
            "        [-3.0663, -2.9264, -4.9186,  ..., -5.1522, -2.3728, -4.1974],\n",
            "        ...,\n",
            "        [-3.1387, -2.8481, -4.7555,  ..., -4.8676, -2.6136, -4.1751],\n",
            "        [-3.1668, -2.9258, -4.5990,  ..., -4.7348, -2.3312, -4.0060],\n",
            "        [-3.0315, -2.9038, -4.7342,  ..., -4.9282, -2.4450, -4.1899]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.0360, -2.9772, -4.0108,  ..., -4.2345, -2.7223, -3.3621],\n",
            "        [-3.0934, -2.9525, -4.4758,  ..., -4.5851, -2.4427, -3.7145],\n",
            "        [-3.0582, -2.9142, -4.8346,  ..., -4.8536, -2.3391, -3.7299],\n",
            "        ...,\n",
            "        [-3.0357, -2.8959, -4.4095,  ..., -4.5764, -2.5114, -3.4264],\n",
            "        [-3.0569, -2.9588, -4.3377,  ..., -4.4950, -2.5274, -3.7142],\n",
            "        [-3.0461, -3.0141, -4.3806,  ..., -4.4264, -2.5466, -3.5580]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.9761, -2.9568, -4.3393,  ..., -4.3604, -2.6136, -3.4888],\n",
            "        [-2.9145, -3.0204, -4.0390,  ..., -4.1251, -2.6414, -3.3568],\n",
            "        [-3.0205, -2.8801, -4.7988,  ..., -5.1217, -2.3364, -3.6635],\n",
            "        ...,\n",
            "        [-2.9663, -2.9390, -4.3444,  ..., -4.6061, -2.5192, -3.3260],\n",
            "        [-3.1262, -2.8744, -4.6581,  ..., -4.9178, -2.5643, -3.6573],\n",
            "        [-3.0984, -3.0275, -4.6782,  ..., -4.9055, -2.6234, -3.5066]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.7908, -2.9539, -4.3640,  ..., -4.3898, -2.6741, -3.3489],\n",
            "        [-2.9282, -2.9300, -4.5854,  ..., -4.6191, -2.6418, -3.5081],\n",
            "        [-2.9416, -2.8936, -4.3220,  ..., -4.3942, -2.7248, -3.2850],\n",
            "        ...,\n",
            "        [-2.8621, -2.8377, -4.0998,  ..., -4.2744, -2.7872, -3.2696],\n",
            "        [-3.0131, -3.0802, -4.4620,  ..., -4.6013, -2.7126, -3.2586],\n",
            "        [-2.8013, -3.0963, -4.1672,  ..., -4.1953, -2.6957, -3.1827]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8621, -2.9951, -3.9082,  ..., -4.0691, -2.9313, -3.1826],\n",
            "        [-2.5596, -2.9822, -3.9573,  ..., -4.0173, -2.7887, -3.1742],\n",
            "        [-2.8216, -2.8693, -4.2072,  ..., -4.2029, -2.8378, -3.2349],\n",
            "        ...,\n",
            "        [-2.9436, -3.0213, -4.4436,  ..., -4.4445, -2.8242, -3.2759],\n",
            "        [-2.9229, -2.9715, -4.0133,  ..., -4.0398, -2.8452, -3.1958],\n",
            "        [-2.8931, -2.9700, -4.3386,  ..., -4.4372, -2.9565, -3.2823]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8582, -2.9218, -4.2105,  ..., -4.2694, -2.9080, -3.2807],\n",
            "        [-2.8717, -2.9287, -4.0661,  ..., -4.1552, -2.9228, -3.1974],\n",
            "        [-2.8433, -2.9440, -4.1095,  ..., -4.1164, -2.8638, -3.2438],\n",
            "        ...,\n",
            "        [-2.9953, -2.8961, -4.1989,  ..., -4.3349, -2.9855, -3.2054],\n",
            "        [-2.8508, -2.8461, -4.2656,  ..., -4.3613, -2.9394, -3.1423],\n",
            "        [-2.9735, -2.9461, -4.3013,  ..., -4.4617, -2.9345, -3.2520]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.9811, -2.8516, -4.4993,  ..., -4.8085, -2.9252, -3.3747],\n",
            "        [-2.9829, -2.8283, -4.1727,  ..., -4.3644, -2.9827, -3.2411],\n",
            "        [-3.0023, -3.0076, -4.3502,  ..., -4.4767, -3.0124, -3.2789],\n",
            "        ...,\n",
            "        [-2.8969, -2.9243, -4.3747,  ..., -4.4220, -2.8263, -3.2985],\n",
            "        [-2.9502, -2.9293, -4.2116,  ..., -4.3470, -2.9209, -3.2748],\n",
            "        [-3.0395, -3.0225, -4.5516,  ..., -4.6505, -2.7945, -3.3740]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.6183, -2.8684, -4.3412,  ..., -4.4168, -2.9056, -3.2826],\n",
            "        [-3.0420, -3.0078, -4.5955,  ..., -4.7329, -3.0330, -3.4078],\n",
            "        [-3.0974, -2.8727, -4.6247,  ..., -4.8054, -3.0108, -3.4357],\n",
            "        ...,\n",
            "        [-2.9808, -2.8361, -4.7403,  ..., -4.8946, -3.0241, -3.4720],\n",
            "        [-2.7031, -2.7730, -4.2565,  ..., -4.4107, -3.0110, -3.2992],\n",
            "        [-3.1128, -2.8963, -4.7590,  ..., -5.0557, -3.0252, -3.5151]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8804, -2.8205, -4.4355,  ..., -4.5255, -3.0381, -3.2781],\n",
            "        [-3.1826, -2.9561, -4.5882,  ..., -4.7718, -2.8982, -3.4946],\n",
            "        [-3.0652, -2.8792, -4.9780,  ..., -5.0236, -3.0415, -3.6108],\n",
            "        ...,\n",
            "        [-3.0136, -2.8381, -4.7054,  ..., -4.8172, -2.9612, -3.4550],\n",
            "        [-3.0601, -2.8899, -4.7415,  ..., -5.1573, -2.9455, -3.5057],\n",
            "        [-3.1828, -2.8954, -4.9154,  ..., -5.0992, -3.0165, -3.5948]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.1079, -2.8795, -4.8312,  ..., -5.0756, -2.7545, -3.5266],\n",
            "        [-3.0118, -2.9075, -4.8840,  ..., -4.9681, -2.9038, -3.5528],\n",
            "        [-2.6017, -2.8391, -4.6349,  ..., -4.6987, -2.8147, -3.4867],\n",
            "        ...,\n",
            "        [-2.9848, -2.9398, -4.7953,  ..., -4.8849, -2.8271, -3.5760],\n",
            "        [-3.1155, -2.7924, -4.8546,  ..., -5.1502, -2.9897, -3.5848],\n",
            "        [-3.1934, -2.7377, -4.7828,  ..., -5.1496, -3.0544, -3.6203]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.3299, -2.8817, -5.2158,  ..., -5.6005, -2.8752, -3.7573],\n",
            "        [-3.1715, -2.7069, -5.1429,  ..., -5.4408, -2.9990, -3.7058],\n",
            "        [-3.3043, -2.8651, -5.1767,  ..., -5.4760, -2.8524, -3.7825],\n",
            "        ...,\n",
            "        [-3.2495, -2.8852, -5.6490,  ..., -6.0625, -2.9914, -3.8612],\n",
            "        [-2.9912, -2.8884, -4.9015,  ..., -5.1519, -2.8467, -3.5664],\n",
            "        [-2.8032, -2.8255, -4.8452,  ..., -4.9775, -2.8753, -3.4326]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.2469, -2.8989, -5.6103,  ..., -5.8954, -2.9398, -3.9164],\n",
            "        [-3.0920, -2.8007, -5.2870,  ..., -5.7472, -2.7470, -3.7570],\n",
            "        [-2.5997, -2.8552, -4.7753,  ..., -4.8984, -2.6915, -3.5758],\n",
            "        ...,\n",
            "        [-2.5429, -2.9055, -4.4278,  ..., -4.5892, -2.6946, -3.4156],\n",
            "        [-2.6744, -2.7619, -4.7638,  ..., -4.9010, -2.7232, -3.4046],\n",
            "        [-2.9090, -2.8667, -5.1863,  ..., -5.3346, -2.8202, -3.6609]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.9565, -2.8297, -5.3994,  ..., -5.6708, -2.7461, -3.8094],\n",
            "        [-2.7427, -2.8044, -5.0817,  ..., -5.1439, -2.7534, -3.6454],\n",
            "        [-2.9566, -2.8866, -5.0013,  ..., -5.2054, -2.8548, -3.6727],\n",
            "        ...,\n",
            "        [-2.9738, -2.8048, -5.3534,  ..., -5.5363, -2.8576, -3.8886],\n",
            "        [-3.0823, -2.9045, -5.2054,  ..., -5.4803, -2.7654, -3.7941],\n",
            "        [-3.0316, -2.7209, -5.6322,  ..., -5.8495, -2.6878, -4.0831]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.9152, -2.6564, -5.1547,  ..., -5.1796, -2.8121, -3.7603],\n",
            "        [-2.3971, -2.7660, -5.0515,  ..., -4.8359, -2.7160, -3.6961],\n",
            "        [-2.7334, -2.7153, -4.8797,  ..., -4.8477, -2.7190, -3.6813],\n",
            "        ...,\n",
            "        [-2.9047, -2.7450, -5.5209,  ..., -5.6136, -2.7633, -3.9296],\n",
            "        [-2.6944, -2.7522, -5.4324,  ..., -5.2984, -2.8342, -3.7570],\n",
            "        [-3.0143, -2.6737, -5.3392,  ..., -5.3840, -2.7533, -3.6951]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8142, -2.7073, -4.9448,  ..., -4.7911, -2.7864, -3.6837],\n",
            "        [-2.4672, -2.7866, -5.0233,  ..., -4.8249, -2.5336, -3.7211],\n",
            "        [-2.8851, -2.7482, -4.8604,  ..., -4.7892, -2.7217, -3.8010],\n",
            "        ...,\n",
            "        [-2.2038, -3.0135, -4.5932,  ..., -4.2765, -2.7193, -3.4783],\n",
            "        [-2.7055, -2.7664, -4.9918,  ..., -5.0150, -2.6627, -3.7107],\n",
            "        [-2.7093, -2.7446, -5.2086,  ..., -5.2927, -2.7583, -3.6587]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.0088, -2.7183, -5.6425,  ..., -5.3419, -2.7856, -4.0116],\n",
            "        [-3.0902, -2.7683, -5.7591,  ..., -5.5532, -2.6900, -4.0085],\n",
            "        [-2.9207, -2.7181, -5.3332,  ..., -5.1084, -2.8160, -3.8454],\n",
            "        ...,\n",
            "        [-2.7104, -2.6587, -5.3131,  ..., -5.1341, -2.6685, -3.8031],\n",
            "        [-2.3891, -2.8619, -5.1277,  ..., -4.7857, -2.6335, -3.6785],\n",
            "        [-3.0348, -2.9079, -5.2851,  ..., -5.1541, -2.8002, -3.8697]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.3391, -2.8823, -6.0991,  ..., -5.9843, -2.7421, -4.3325],\n",
            "        [-2.5727, -2.9391, -5.1650,  ..., -4.8490, -2.6686, -3.8640],\n",
            "        [-2.7416, -2.8002, -5.3585,  ..., -5.0323, -2.7346, -3.9976],\n",
            "        ...,\n",
            "        [-3.5396, -2.9035, -5.8252,  ..., -5.6559, -2.8096, -4.2273],\n",
            "        [-3.1011, -2.8185, -5.4422,  ..., -5.4725, -2.7612, -3.9396],\n",
            "        [-2.7566, -2.8624, -5.0888,  ..., -4.7908, -2.7773, -3.7819]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.6896, -3.0220, -4.8833,  ..., -4.8150, -2.6122, -3.6557],\n",
            "        [-2.8969, -2.8897, -5.4320,  ..., -5.0763, -2.7261, -4.0999],\n",
            "        [-3.1791, -2.9526, -5.6893,  ..., -5.3123, -2.7738, -4.1344],\n",
            "        ...,\n",
            "        [-2.8474, -2.9047, -5.6662,  ..., -5.3759, -2.7528, -4.0796],\n",
            "        [-2.7605, -3.0621, -5.2660,  ..., -4.8289, -2.4472, -3.8701],\n",
            "        [-3.0643, -2.9800, -5.7681,  ..., -5.4530, -2.7211, -4.0608]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.1124, -3.1409, -5.7880,  ..., -5.3560, -2.7032, -4.2220],\n",
            "        [-2.4821, -3.0565, -5.0162,  ..., -4.6763, -2.6544, -3.7464],\n",
            "        [-2.3486, -2.8610, -5.6378,  ..., -5.0980, -2.4405, -4.1197],\n",
            "        ...,\n",
            "        [-1.6381, -3.3503, -5.0242,  ..., -4.4841, -2.4011, -3.8354],\n",
            "        [-2.9175, -2.9900, -5.3981,  ..., -5.0997, -2.6033, -3.9896],\n",
            "        [-2.3763, -3.0610, -5.1080,  ..., -4.6242, -2.6207, -3.7900]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.3814, -3.0955, -6.4462,  ..., -5.9309, -2.7432, -4.6205],\n",
            "        [-3.3373, -3.1222, -6.1584,  ..., -5.5446, -2.8038, -4.5026],\n",
            "        [-3.0520, -3.0618, -5.6813,  ..., -5.1701, -2.6599, -4.2945],\n",
            "        ...,\n",
            "        [-3.6059, -3.2056, -5.9472,  ..., -5.4401, -2.9164, -4.4323],\n",
            "        [-1.4105, -3.2588, -5.3840,  ..., -4.7155, -2.5712, -3.8896],\n",
            "        [-2.5467, -3.1366, -5.0905,  ..., -4.6124, -2.5847, -3.8774]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.4866, -2.9302, -5.5477,  ..., -4.8945, -2.5790, -4.1155],\n",
            "        [-3.9770, -3.1636, -7.1677,  ..., -6.3252, -2.9717, -5.2600],\n",
            "        [-2.7098, -3.0975, -5.6756,  ..., -5.0385, -2.8215, -4.2357],\n",
            "        ...,\n",
            "        [-4.3729, -3.2620, -7.1341,  ..., -6.5817, -3.1930, -5.0330],\n",
            "        [-3.2359, -3.1933, -6.4099,  ..., -5.7655, -2.9422, -4.5133],\n",
            "        [-3.2618, -3.0160, -6.1293,  ..., -5.6654, -2.7717, -4.5668]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.9370, -2.9570, -5.5725,  ..., -5.0245, -2.9531, -4.1380],\n",
            "        [-4.0129, -3.0729, -6.9127,  ..., -6.5071, -3.0670, -5.1259],\n",
            "        [-3.2935, -3.0084, -6.1624,  ..., -5.5917, -3.0918, -4.4361],\n",
            "        ...,\n",
            "        [-2.8025, -3.0168, -5.8206,  ..., -5.3180, -2.7263, -4.2477],\n",
            "        [-3.3834, -3.1592, -6.2409,  ..., -5.4621, -2.7858, -4.6327],\n",
            "        [-4.5488, -3.2129, -7.8788,  ..., -7.5446, -3.2156, -5.5750]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.8527, -3.1591, -6.4105,  ..., -5.7501, -3.2484, -4.7615],\n",
            "        [-3.2598, -2.9824, -5.7405,  ..., -5.2672, -3.1765, -4.2566],\n",
            "        [-3.9986, -3.1821, -6.4715,  ..., -5.8113, -3.0542, -4.9614],\n",
            "        ...,\n",
            "        [-3.9857, -3.2167, -6.6429,  ..., -5.9111, -3.3365, -4.7064],\n",
            "        [-3.7225, -3.0782, -6.7313,  ..., -5.8491, -3.1527, -4.8605],\n",
            "        [-3.5268, -3.0077, -6.1003,  ..., -5.5090, -3.1275, -4.4410]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.7218, -2.9420, -5.3661,  ..., -4.8058, -2.8760, -4.0891],\n",
            "        [-3.1112, -3.1079, -5.8789,  ..., -5.1723, -3.0373, -4.4567],\n",
            "        [-3.6346, -2.9316, -5.9512,  ..., -5.5136, -3.1565, -4.3649],\n",
            "        ...,\n",
            "        [-3.8460, -3.0399, -6.4387,  ..., -5.8031, -3.1801, -4.7600],\n",
            "        [-3.8680, -3.1184, -6.6703,  ..., -6.0786, -3.3426, -5.0519],\n",
            "        [-4.5668, -3.2367, -7.2655,  ..., -6.5700, -3.5592, -5.3995]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.0510, -3.0329, -6.7146,  ..., -5.9485, -3.3550, -5.0462],\n",
            "        [-4.3695, -3.2645, -6.5640,  ..., -6.2227, -3.1771, -5.1035],\n",
            "        [-3.8224, -3.1996, -6.7625,  ..., -5.8556, -3.1430, -4.8572],\n",
            "        ...,\n",
            "        [-3.2800, -2.8783, -6.1757,  ..., -5.4011, -2.8528, -4.4764],\n",
            "        [-4.1256, -3.0632, -6.7263,  ..., -6.0133, -3.3173, -4.7153],\n",
            "        [-3.9085, -3.0670, -6.7144,  ..., -5.9051, -3.2468, -4.9291]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8795, -2.9180, -5.7220,  ..., -5.1470, -2.9095, -4.2762],\n",
            "        [-3.0116, -2.9946, -5.5645,  ..., -4.8618, -2.8669, -4.1565],\n",
            "        [-3.3360, -2.8669, -5.6858,  ..., -5.1836, -3.1668, -4.2853],\n",
            "        ...,\n",
            "        [-2.9130, -2.9814, -5.4568,  ..., -4.6606, -2.9835, -4.2297],\n",
            "        [-4.4207, -3.1377, -7.2396,  ..., -6.6238, -3.4602, -5.1692],\n",
            "        [-3.0236, -2.9159, -5.6981,  ..., -5.1843, -2.8015, -4.2958]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.7697, -2.8828, -6.4277,  ..., -5.8964, -3.1188, -4.9347],\n",
            "        [-2.6467, -2.8410, -5.8795,  ..., -5.1344, -2.8825, -4.3589],\n",
            "        [-3.6739, -2.7656, -5.9790,  ..., -5.3401, -3.2478, -4.3760],\n",
            "        ...,\n",
            "        [-3.3690, -2.9936, -6.2142,  ..., -5.4568, -3.1769, -4.6335],\n",
            "        [-3.3364, -3.0297, -6.5513,  ..., -5.6493, -3.3115, -4.7847],\n",
            "        [-4.2083, -2.9607, -6.5775,  ..., -5.8681, -3.2294, -5.0050]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.6885, -3.1541, -6.7491,  ..., -6.1515, -3.4201, -5.0371],\n",
            "        [-2.1676, -2.8945, -5.3607,  ..., -4.6323, -2.9313, -4.0961],\n",
            "        [-3.6647, -2.7877, -5.9446,  ..., -5.3787, -3.2471, -4.6460],\n",
            "        ...,\n",
            "        [-3.3669, -2.7042, -5.8612,  ..., -5.1862, -3.2125, -4.5095],\n",
            "        [-2.9583, -2.7934, -6.0025,  ..., -5.3494, -2.7115, -4.5035],\n",
            "        [-1.8273, -2.8538, -5.5365,  ..., -4.8281, -2.6736, -4.1793]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.6746, -2.6240, -5.4456,  ..., -4.9344, -3.1153, -4.3038],\n",
            "        [-3.9815, -2.6438, -5.7170,  ..., -5.3522, -3.3370, -4.8018],\n",
            "        [-3.6526, -2.7488, -5.6145,  ..., -4.9439, -3.2696, -4.4528],\n",
            "        ...,\n",
            "        [-2.4848, -2.7422, -5.4534,  ..., -4.7810, -2.7981, -4.2128],\n",
            "        [-5.3151, -2.9862, -7.4166,  ..., -6.5144, -3.6691, -5.5622],\n",
            "        [-4.0469, -2.6664, -6.0055,  ..., -5.4728, -3.1964, -4.5950]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.3463, -2.5882, -5.1871,  ..., -4.6925, -2.8994, -4.2959],\n",
            "        [-3.5716, -2.4317, -5.2924,  ..., -4.9065, -3.1084, -4.1478],\n",
            "        [-3.7648, -2.8964, -5.3493,  ..., -4.8364, -3.0259, -4.4125],\n",
            "        ...,\n",
            "        [-5.7418, -2.8467, -7.1576,  ..., -6.5854, -3.5536, -5.6001],\n",
            "        [-3.8111, -2.5687, -5.8375,  ..., -4.9702, -3.3011, -4.5583],\n",
            "        [-4.0517, -2.6509, -5.9437,  ..., -5.4332, -3.2975, -4.7591]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.4876, -2.4949, -6.1238,  ..., -5.3242, -3.2028, -4.8093],\n",
            "        [-0.9283, -3.1080, -6.2852,  ..., -5.4400, -2.7457, -4.7602],\n",
            "        [-4.2678, -2.4514, -5.9061,  ..., -5.3991, -3.2504, -4.7258],\n",
            "        ...,\n",
            "        [-4.5350, -2.6810, -6.0071,  ..., -5.5666, -3.0171, -4.8246],\n",
            "        [-5.7123, -2.6834, -7.2344,  ..., -6.5207, -3.7520, -5.6138],\n",
            "        [-4.6237, -2.4891, -6.4353,  ..., -5.9300, -3.1274, -5.0126]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.0732, -2.3518, -5.3174,  ..., -4.5648, -3.1487, -4.1363],\n",
            "        [-3.9975, -2.4453, -5.7779,  ..., -5.1819, -3.3269, -4.7764],\n",
            "        [-4.3890, -2.4622, -6.1936,  ..., -5.5565, -3.4338, -4.9546],\n",
            "        ...,\n",
            "        [-4.6748, -2.3498, -6.4507,  ..., -5.7088, -3.5735, -5.1078],\n",
            "        [-4.4275, -2.4425, -6.4605,  ..., -5.6438, -3.5069, -4.9302],\n",
            "        [-0.6480, -3.1754, -6.8572,  ..., -6.1428, -2.9500, -5.1990]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.4726, -2.3240, -6.3554,  ..., -5.6389, -3.5530, -5.2080],\n",
            "        [-4.7337, -2.2320, -6.4521,  ..., -5.8073, -3.4019, -5.2618],\n",
            "        [-4.5858, -2.3428, -6.2865,  ..., -5.5041, -3.6626, -5.1363],\n",
            "        ...,\n",
            "        [-5.0792, -2.0905, -6.6839,  ..., -6.3425, -3.7672, -5.5137],\n",
            "        [-5.1631, -2.2090, -6.7159,  ..., -6.2310, -3.5589, -5.4773],\n",
            "        [-4.5712, -2.3067, -6.6061,  ..., -6.0367, -3.4678, -5.3636]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.9978, -2.0898, -7.1764,  ..., -6.1808, -3.5043, -5.4735],\n",
            "        [-3.6226, -2.1614, -6.1154,  ..., -5.2948, -3.4643, -4.9660],\n",
            "        [-4.1749, -2.0712, -6.6189,  ..., -6.0958, -3.6937, -5.3360],\n",
            "        ...,\n",
            "        [-4.7549, -1.9591, -6.9199,  ..., -6.2390, -3.7575, -5.5089],\n",
            "        [-5.3248, -2.2260, -7.3590,  ..., -6.5289, -3.9172, -5.8731],\n",
            "        [-5.0784, -2.2859, -7.1031,  ..., -6.5543, -3.7869, -5.7656]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.8515, -2.1909, -6.9269,  ..., -5.9307, -3.6551, -5.1552],\n",
            "        [-5.9753, -2.3323, -7.7736,  ..., -7.1294, -4.1268, -6.2006],\n",
            "        [-5.6207, -2.0756, -8.0248,  ..., -7.1393, -4.1411, -6.1417],\n",
            "        ...,\n",
            "        [-5.7694, -2.2008, -7.7042,  ..., -6.8292, -4.1399, -5.9555],\n",
            "        [-0.9209, -2.5335, -7.6608,  ..., -6.3183, -3.4694, -5.7569],\n",
            "        [-4.8401, -2.1959, -7.0631,  ..., -6.1882, -3.9967, -5.4338]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.8864,  -2.2638,  -8.6069,  ...,  -7.5785,  -4.5440,  -6.7510],\n",
            "        [ -8.4645,  -2.6459, -10.1482,  ...,  -9.0613,  -5.1709,  -7.6920],\n",
            "        [ -4.3222,  -2.1707,  -7.1921,  ...,  -5.9827,  -3.9696,  -5.6250],\n",
            "        ...,\n",
            "        [ -4.8155,  -2.2014,  -7.6126,  ...,  -6.4713,  -4.1056,  -5.9188],\n",
            "        [ -3.8498,  -2.3111,  -7.4334,  ...,  -5.9547,  -3.9514,  -5.6656],\n",
            "        [ -3.8922,  -2.1314,  -7.2641,  ...,  -5.9891,  -3.9836,  -5.7463]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.4747, -1.9861, -7.0660,  ..., -6.0107, -4.0064, -5.4592],\n",
            "        [-4.0180, -1.9784, -6.9421,  ..., -5.6333, -4.0048, -5.4126],\n",
            "        [-1.4048, -2.2297, -7.5590,  ..., -5.9764, -3.7839, -5.7467],\n",
            "        ...,\n",
            "        [-7.3650, -2.3957, -9.8062,  ..., -7.7960, -5.1539, -7.4771],\n",
            "        [-0.6152, -2.9797, -8.4434,  ..., -6.7866, -3.9308, -6.3077],\n",
            "        [-5.2375, -2.1394, -7.6839,  ..., -6.4568, -4.5233, -5.9757]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.3744, -2.3141, -8.2155,  ..., -6.7806, -4.7526, -6.4604],\n",
            "        [-7.1722, -2.4368, -9.2829,  ..., -7.6763, -5.2730, -7.4520],\n",
            "        [-5.6189, -2.1513, -7.9104,  ..., -6.5186, -4.6368, -6.3134],\n",
            "        ...,\n",
            "        [-3.4148, -2.2711, -6.9635,  ..., -5.6657, -4.0674, -5.7390],\n",
            "        [-3.6895, -2.1443, -7.0540,  ..., -5.4845, -4.2972, -5.4541],\n",
            "        [-7.0934, -2.5109, -8.9340,  ..., -7.3377, -5.1003, -7.0946]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-0.5641, -3.0060, -8.8177,  ..., -7.0447, -4.1416, -6.9540],\n",
            "        [-6.5104, -2.4479, -8.3507,  ..., -6.6348, -4.6575, -6.7651],\n",
            "        [-6.3717, -2.4456, -7.6757,  ..., -6.3705, -4.6971, -6.5347],\n",
            "        ...,\n",
            "        [-4.9310, -2.2877, -7.4064,  ..., -5.6585, -4.3387, -6.0305],\n",
            "        [-6.1394, -2.2976, -7.6868,  ..., -6.2226, -4.4071, -6.1172],\n",
            "        [-6.1617, -2.3188, -7.8431,  ..., -6.4365, -4.4290, -6.5145]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.4563, -2.3132, -6.2321,  ..., -5.2638, -3.9919, -5.4325],\n",
            "        [-4.8058, -2.1725, -6.8043,  ..., -5.2589, -3.8630, -5.4599],\n",
            "        [-3.9761, -1.9173, -6.7586,  ..., -5.5513, -3.9303, -5.4504],\n",
            "        ...,\n",
            "        [-5.2096, -2.4434, -7.4023,  ..., -5.5696, -4.2838, -5.8453],\n",
            "        [-3.6587, -2.1321, -7.2783,  ..., -5.5363, -4.0953, -5.7550],\n",
            "        [-5.4160, -2.4750, -7.6159,  ..., -5.9354, -4.4887, -6.1911]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.3661, -2.1699, -6.3506,  ..., -4.9109, -3.8079, -5.1979],\n",
            "        [-5.0595, -2.3937, -6.9423,  ..., -5.1511, -3.9450, -5.5559],\n",
            "        [-4.9781, -2.4526, -6.8460,  ..., -5.1509, -4.1438, -5.5930],\n",
            "        ...,\n",
            "        [-6.4763, -2.3580, -7.9546,  ..., -6.1182, -4.4164, -6.4062],\n",
            "        [-2.4018, -2.4947, -6.9418,  ..., -4.8498, -3.9407, -5.6101],\n",
            "        [-5.2787, -2.5900, -6.9385,  ..., -5.3387, -4.2363, -5.8632]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-0.3869, -3.7832, -8.3980,  ..., -6.4768, -4.0939, -6.8287],\n",
            "        [-4.9342, -2.5232, -7.0157,  ..., -4.9900, -4.0796, -5.7290],\n",
            "        [-3.5843, -2.5585, -5.9686,  ..., -4.4274, -3.7949, -4.9712],\n",
            "        ...,\n",
            "        [-5.3738, -2.3697, -6.9513,  ..., -5.2721, -3.9067, -5.8432],\n",
            "        [-4.4073, -2.4224, -6.4017,  ..., -4.5895, -3.7118, -5.0643],\n",
            "        [-6.6615, -2.6068, -7.8281,  ..., -5.9773, -4.2014, -6.2842]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.0324, -2.7077, -6.1219,  ..., -4.5973, -3.8106, -5.3129],\n",
            "        [-5.3018, -2.4438, -6.2824,  ..., -4.7715, -3.8631, -5.2000],\n",
            "        [-4.0995, -2.6792, -5.4728,  ..., -4.1526, -3.4939, -4.6548],\n",
            "        ...,\n",
            "        [-4.1402, -2.5507, -5.4935,  ..., -4.2452, -3.3795, -4.8861],\n",
            "        [-5.2425, -2.5426, -6.2737,  ..., -4.6712, -3.8468, -5.2200],\n",
            "        [-5.8913, -2.6383, -6.6030,  ..., -5.0695, -3.9494, -5.4837]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.8589, -2.8840, -7.2006,  ..., -5.4652, -4.0384, -5.8558],\n",
            "        [-4.1453, -2.7982, -5.2921,  ..., -3.8526, -3.6005, -4.5001],\n",
            "        [-5.6885, -2.7244, -6.3180,  ..., -4.8910, -3.6997, -5.3480],\n",
            "        ...,\n",
            "        [-5.3580, -2.6673, -6.1932,  ..., -4.6144, -3.7279, -5.0699],\n",
            "        [-6.0047, -2.7902, -6.9114,  ..., -5.0453, -4.0858, -5.6066],\n",
            "        [-5.1675, -2.7018, -5.8160,  ..., -4.3856, -3.6328, -4.8488]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.1376, -2.8646, -4.9700,  ..., -3.6116, -3.4402, -4.1925],\n",
            "        [-4.8830, -2.9784, -5.6626,  ..., -4.0213, -3.5927, -4.6431],\n",
            "        [-4.3340, -2.6505, -5.1760,  ..., -3.8479, -3.3036, -4.3044],\n",
            "        ...,\n",
            "        [-4.5856, -2.7034, -5.4007,  ..., -3.8111, -3.3916, -4.3026],\n",
            "        [-5.2280, -2.7169, -5.6518,  ..., -4.3493, -3.5489, -4.6002],\n",
            "        [-3.8819, -2.7989, -5.7679,  ..., -3.8277, -3.3927, -4.6676]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.8625, -2.9725, -4.7647,  ..., -3.3292, -3.2345, -3.8494],\n",
            "        [-4.5917, -3.0425, -5.1118,  ..., -3.6012, -3.4565, -4.1896],\n",
            "        [-2.3820, -2.9360, -4.6966,  ..., -3.4523, -3.0259, -3.8063],\n",
            "        ...,\n",
            "        [-5.3387, -2.8981, -5.6420,  ..., -4.1158, -3.4168, -4.6935],\n",
            "        [-5.7609, -2.8366, -6.1188,  ..., -4.4255, -3.4953, -4.9628],\n",
            "        [-2.0504, -2.9509, -4.6422,  ..., -3.4405, -3.1810, -3.7886]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.1182, -2.9997, -4.2843,  ..., -3.1252, -3.2784, -3.5129],\n",
            "        [-4.1344, -2.9578, -4.3316,  ..., -3.3980, -3.1390, -3.6560],\n",
            "        [-3.8501, -2.9479, -4.4267,  ..., -3.2132, -3.2687, -3.6939],\n",
            "        ...,\n",
            "        [-4.0999, -2.9395, -4.6603,  ..., -3.3500, -3.3403, -3.7920],\n",
            "        [-5.1108, -2.8201, -5.4778,  ..., -3.9567, -3.4392, -4.3834],\n",
            "        [-5.2592, -3.0271, -5.9827,  ..., -3.8796, -3.5915, -4.6596]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.7137, -3.0774, -4.6233,  ..., -3.2748, -3.2480, -3.6928],\n",
            "        [-5.0448, -2.9893, -5.4166,  ..., -3.9418, -3.3770, -4.1496],\n",
            "        [-4.9341, -2.8178, -5.3785,  ..., -3.8459, -3.3398, -4.2850],\n",
            "        ...,\n",
            "        [-4.3412, -3.0266, -4.6741,  ..., -3.4678, -3.3074, -3.8640],\n",
            "        [-3.9801, -3.0001, -4.3717,  ..., -3.3257, -3.1131, -3.6927],\n",
            "        [-3.2878, -3.0673, -4.5104,  ..., -3.2401, -3.2180, -3.6035]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.0526, -3.0206, -5.4114,  ..., -3.8973, -3.2575, -4.2901],\n",
            "        [-4.4809, -2.9490, -4.8415,  ..., -3.5949, -3.1520, -3.9444],\n",
            "        [-6.7127, -3.3205, -7.4787,  ..., -4.5812, -3.7288, -5.2291],\n",
            "        ...,\n",
            "        [-4.6956, -2.9581, -4.8773,  ..., -3.4983, -3.1226, -3.9585],\n",
            "        [-5.4847, -3.0420, -5.9730,  ..., -4.0760, -3.5421, -4.5017],\n",
            "        [-4.1659, -3.0149, -5.2721,  ..., -3.4190, -3.2797, -3.9337]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.0947, -3.0201, -6.1448,  ..., -4.2492, -3.3585, -4.6495],\n",
            "        [-4.3788, -2.8846, -4.8572,  ..., -3.4757, -3.2797, -3.7598],\n",
            "        [-4.8507, -2.9501, -5.4272,  ..., -3.6397, -3.2925, -3.8504],\n",
            "        ...,\n",
            "        [-4.2322, -2.9968, -4.8846,  ..., -3.3441, -3.2515, -3.6263],\n",
            "        [-5.2507, -2.9373, -5.7090,  ..., -4.0789, -3.3619, -4.1298],\n",
            "        [-4.5616, -3.0228, -5.2539,  ..., -3.5036, -3.3780, -3.8801]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-0.7939, -3.5686, -6.2972,  ..., -4.2738, -3.2944, -3.9934],\n",
            "        [-5.4596, -3.1722, -6.0507,  ..., -3.9750, -3.2746, -4.3557],\n",
            "        [-4.3063, -2.9670, -4.8911,  ..., -3.4489, -3.1109, -3.6866],\n",
            "        ...,\n",
            "        [-4.5544, -2.9091, -5.1504,  ..., -3.4755, -3.2155, -3.6687],\n",
            "        [-7.0583, -3.2995, -7.4314,  ..., -4.5749, -3.5255, -5.0313],\n",
            "        [-5.7552, -3.1303, -6.2405,  ..., -4.2003, -3.3342, -4.3147]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.1771, -3.0079, -5.4516,  ..., -4.0744, -3.1136, -4.0166],\n",
            "        [-4.7253, -2.9289, -5.3086,  ..., -3.7381, -3.0395, -3.6838],\n",
            "        [-3.4187, -2.9259, -4.6145,  ..., -3.2384, -3.0555, -3.3107],\n",
            "        ...,\n",
            "        [-4.5827, -2.8063, -5.2496,  ..., -3.7796, -2.9255, -3.6211],\n",
            "        [-5.2492, -2.9891, -6.0173,  ..., -3.9968, -3.0430, -3.9723],\n",
            "        [-5.3443, -3.0023, -6.0288,  ..., -4.1803, -3.0477, -4.0549]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.7649, -2.8960, -4.8935,  ..., -3.5490, -2.8401, -3.4235],\n",
            "        [-5.0008, -2.8323, -5.8713,  ..., -3.9960, -2.9356, -3.8164],\n",
            "        [-6.6714, -3.1957, -7.6959,  ..., -4.8280, -3.4240, -4.8714],\n",
            "        ...,\n",
            "        [-5.4781, -2.9140, -6.3724,  ..., -4.3132, -3.2269, -4.1225],\n",
            "        [-4.9434, -2.7062, -6.0155,  ..., -3.8822, -3.0699, -3.9686],\n",
            "        [-3.2080, -2.9830, -5.1161,  ..., -3.3926, -3.1265, -3.4937]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.2655, -2.8473, -6.7431,  ..., -4.2011, -2.9653, -4.0683],\n",
            "        [-5.0200, -2.7839, -6.2577,  ..., -4.1751, -3.1270, -4.0254],\n",
            "        [-5.0634, -3.0631, -6.4793,  ..., -3.9506, -2.9296, -4.0789],\n",
            "        ...,\n",
            "        [-2.3597, -2.9483, -5.2987,  ..., -3.6153, -2.8118, -3.2484],\n",
            "        [-5.0641, -3.0597, -6.2179,  ..., -4.1958, -3.0816, -4.0506],\n",
            "        [-3.7835, -2.6840, -5.8532,  ..., -3.7356, -2.8724, -3.5277]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.9932, -2.5779, -5.9644,  ..., -3.9938, -2.7643, -3.4835],\n",
            "        [-2.5947, -2.5437, -6.4139,  ..., -3.8294, -2.7085, -3.5730],\n",
            "        [-2.8158, -2.4745, -5.7058,  ..., -3.8703, -2.2915, -3.5221],\n",
            "        ...,\n",
            "        [-5.3560, -2.8578, -6.9612,  ..., -4.4443, -2.8314, -4.2101],\n",
            "        [-4.6150, -2.7197, -6.0252,  ..., -4.0466, -2.7134, -3.8221],\n",
            "        [-3.9719, -2.4908, -6.5390,  ..., -4.0232, -2.5046, -3.6905]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -4.5802,  -2.5685,  -7.1268,  ...,  -4.1848,  -3.1324,  -4.0547],\n",
            "        [ -5.3668,  -2.6337,  -7.5166,  ...,  -4.8442,  -2.9331,  -4.4002],\n",
            "        [ -5.6813,  -2.3984,  -7.7702,  ...,  -4.8307,  -2.8743,  -4.4441],\n",
            "        ...,\n",
            "        [ -5.0792,  -2.9183,  -7.5590,  ...,  -4.3155,  -2.9760,  -4.2394],\n",
            "        [ -4.5164,  -2.9355,  -7.8191,  ...,  -4.1634,  -3.3471,  -4.3196],\n",
            "        [ -8.9911,  -3.2768, -11.5425,  ...,  -6.6763,  -3.5336,  -6.2371]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.6061,  -2.3672,  -9.5407,  ...,  -6.0337,  -3.3456,  -4.9596],\n",
            "        [ -5.8298,  -2.3800,  -7.9852,  ...,  -4.9686,  -3.2089,  -4.5640],\n",
            "        [ -7.8649,  -2.7790, -10.3401,  ...,  -6.5062,  -3.6969,  -5.5724],\n",
            "        ...,\n",
            "        [ -4.3929,  -2.3615,  -7.3560,  ...,  -4.3846,  -2.9627,  -3.4713],\n",
            "        [ -7.2742,  -2.5530,  -9.4531,  ...,  -5.8784,  -3.2732,  -4.8913],\n",
            "        [ -8.4714,  -2.9978, -11.1048,  ...,  -6.4254,  -3.2649,  -5.8379]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.4051, -2.5038, -8.8207,  ..., -5.4766, -3.0103, -4.7618],\n",
            "        [-6.9708, -2.2894, -9.0961,  ..., -5.8842, -3.0317, -4.9539],\n",
            "        [-4.7091, -2.8892, -9.5291,  ..., -4.8649, -3.4350, -4.6375],\n",
            "        ...,\n",
            "        [-5.2818, -2.2121, -8.4704,  ..., -4.9443, -2.7599, -4.3634],\n",
            "        [-6.4912, -2.4104, -9.9114,  ..., -5.7982, -2.9488, -5.0348],\n",
            "        [-6.2140, -2.2504, -9.1700,  ..., -5.2495, -2.9424, -4.7054]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -5.0057,  -2.3772,  -8.8608,  ...,  -5.2229,  -2.8276,  -4.1823],\n",
            "        [ -6.9373,  -2.3971,  -9.2587,  ...,  -6.0479,  -2.9353,  -4.9344],\n",
            "        [ -7.6087,  -2.5879, -10.3341,  ...,  -6.3540,  -3.3445,  -5.3531],\n",
            "        ...,\n",
            "        [ -4.9850,  -2.0554,  -8.1415,  ...,  -5.3209,  -2.2967,  -3.9440],\n",
            "        [ -5.9843,  -2.0154,  -8.5175,  ...,  -5.3290,  -2.6297,  -4.7165],\n",
            "        [ -4.9650,  -1.8744,  -9.1087,  ...,  -5.2269,  -2.4227,  -4.4246]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.4017,  -2.7461, -10.0817,  ...,  -6.5313,  -2.6558,  -5.3975],\n",
            "        [ -6.3210,  -2.1287,  -9.7955,  ...,  -5.7356,  -2.6936,  -4.6040],\n",
            "        [ -5.9185,  -1.9193,  -9.7242,  ...,  -5.3631,  -2.5194,  -4.4828],\n",
            "        ...,\n",
            "        [ -8.9658,  -2.3218, -12.7690,  ...,  -7.4301,  -2.9305,  -6.0976],\n",
            "        [ -3.9245,  -2.5431, -10.1005,  ...,  -5.2567,  -2.9556,  -4.3639],\n",
            "        [ -7.2488,  -2.1948, -11.2662,  ...,  -6.3052,  -2.2576,  -5.4660]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -3.2278,  -2.4653,  -9.0210,  ...,  -5.0798,  -2.1792,  -4.0408],\n",
            "        [ -7.7766,  -2.2324, -11.6187,  ...,  -6.7529,  -1.8376,  -5.8156],\n",
            "        [ -8.5337,  -2.2973, -12.2561,  ...,  -7.2068,  -2.5976,  -5.8114],\n",
            "        ...,\n",
            "        [ -6.9009,  -2.3042, -10.6171,  ...,  -6.2395,  -2.2390,  -5.0918],\n",
            "        [ -7.3062,  -2.2257, -10.6210,  ...,  -6.6062,  -2.4581,  -5.2241],\n",
            "        [ -9.5055,  -2.2178, -13.5491,  ...,  -7.8582,  -2.5249,  -6.2669]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.2799,  -2.2709, -12.8894,  ...,  -7.5598,  -1.7614,  -5.5694],\n",
            "        [-10.6336,  -2.7716, -15.7042,  ...,  -8.6840,  -1.8043,  -7.1696],\n",
            "        [ -9.6969,  -2.4380, -13.7396,  ...,  -8.4214,  -1.9407,  -6.7615],\n",
            "        ...,\n",
            "        [ -7.8038,  -2.1546, -10.9922,  ...,  -6.8719,  -2.6886,  -5.8181],\n",
            "        [ -0.4477,  -3.3628, -10.8148,  ...,  -6.2982,  -2.5261,  -4.4832],\n",
            "        [ -6.5929,  -2.2081, -11.0185,  ...,  -6.3385,  -2.0954,  -5.0206]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.2937,  -2.0752, -10.7152,  ...,  -6.2657,  -2.0657,  -5.1544],\n",
            "        [ -7.5865,  -2.3212, -12.6439,  ...,  -7.2986,  -1.5080,  -5.4513],\n",
            "        [ -8.4176,  -2.4556, -14.2653,  ...,  -7.5755,  -1.6787,  -6.1401],\n",
            "        ...,\n",
            "        [ -8.1029,  -2.2272, -11.8716,  ...,  -7.3030,  -1.9283,  -5.6561],\n",
            "        [ -8.8549,  -2.6612, -12.4133,  ...,  -7.3791,  -2.0353,  -6.3630],\n",
            "        [ -5.6049,  -2.5322, -11.0145,  ...,  -5.9670,  -2.0787,  -4.8431]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.1266,  -2.3750, -12.0589,  ...,  -6.5039,  -1.2998,  -5.3001],\n",
            "        [ -9.3166,  -2.8591, -14.0627,  ...,  -8.2117,  -2.1836,  -6.4082],\n",
            "        [ -7.6500,  -2.5764, -12.1205,  ...,  -7.3507,  -1.3005,  -5.9913],\n",
            "        ...,\n",
            "        [ -5.6231,  -2.0772, -10.7064,  ...,  -5.8771,  -1.5406,  -4.9660],\n",
            "        [ -7.4365,  -2.1003, -12.2491,  ...,  -6.9803,  -1.5905,  -5.6908],\n",
            "        [ -5.5623,  -2.3285, -11.5002,  ...,  -6.7981,  -1.0449,  -5.3698]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.4932,  -2.3279, -11.9055,  ...,  -6.0384,  -1.7345,  -5.4662],\n",
            "        [ -5.9596,  -2.5931, -10.4661,  ...,  -5.6027,  -2.4738,  -5.0843],\n",
            "        [ -9.5763,  -2.7946, -13.2509,  ...,  -7.5872,  -2.4102,  -6.2861],\n",
            "        ...,\n",
            "        [ -8.2331,  -2.6883, -11.7072,  ...,  -6.9551,  -2.4958,  -5.8283],\n",
            "        [ -3.7927,  -2.8940, -11.7387,  ...,  -5.4761,  -2.6854,  -4.6501],\n",
            "        [ -7.9471,  -2.9624, -12.9038,  ...,  -6.7052,  -2.3971,  -5.6053]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-11.1779,  -3.2269, -15.7564,  ...,  -8.0738,  -3.0538,  -7.2423],\n",
            "        [ -0.6330,  -3.5463, -11.5883,  ...,  -5.9392,  -3.1975,  -4.2643],\n",
            "        [ -7.9245,  -2.7289, -11.6088,  ...,  -7.1248,  -2.3453,  -5.9217],\n",
            "        ...,\n",
            "        [ -6.6224,  -2.2715, -10.3706,  ...,  -6.0931,  -1.7729,  -5.0285],\n",
            "        [ -6.8258,  -2.7276, -11.9183,  ...,  -5.8691,  -2.1928,  -5.3239],\n",
            "        [ -7.9175,  -2.8244, -12.6974,  ...,  -6.3647,  -2.3790,  -5.7508]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.3476,  -2.4581, -11.7315,  ...,  -5.6059,  -2.5191,  -5.2154],\n",
            "        [ -9.2636,  -2.8929, -12.8860,  ...,  -6.8559,  -2.4883,  -6.3418],\n",
            "        [ -0.1421,  -5.4336, -12.3079,  ...,  -7.2419,  -4.3753,  -5.4102],\n",
            "        ...,\n",
            "        [ -4.6966,  -3.0211, -11.3599,  ...,  -5.5868,  -2.8893,  -4.6522],\n",
            "        [ -7.5061,  -2.1211, -12.1017,  ...,  -6.3579,  -2.1594,  -5.4222],\n",
            "        [ -9.4124,  -2.6616, -13.1604,  ...,  -7.4501,  -2.8560,  -6.5807]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -5.6586,  -3.0581,  -9.5072,  ...,  -4.8121,  -3.2668,  -4.3476],\n",
            "        [ -9.5307,  -3.0797, -11.9114,  ...,  -6.9192,  -3.1927,  -6.4339],\n",
            "        [ -6.3213,  -3.1648, -11.8698,  ...,  -5.1461,  -2.9796,  -5.3862],\n",
            "        ...,\n",
            "        [ -4.5720,  -2.8098,  -9.9353,  ...,  -4.7415,  -3.2577,  -4.4468],\n",
            "        [ -8.0193,  -2.6128, -10.6098,  ...,  -6.1402,  -2.3163,  -5.3845],\n",
            "        [ -7.5926,  -2.1690, -10.8496,  ...,  -5.9327,  -2.8307,  -5.7134]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.4753,  -2.2981,  -9.1863,  ...,  -4.8830,  -2.9679,  -4.7218],\n",
            "        [ -7.7320,  -2.3774, -10.2090,  ...,  -5.4808,  -2.8123,  -5.2036],\n",
            "        [ -7.7960,  -2.8723,  -9.4309,  ...,  -5.5989,  -3.2222,  -5.5036],\n",
            "        ...,\n",
            "        [ -6.8422,  -2.6293,  -9.1883,  ...,  -5.2418,  -2.8500,  -5.0144],\n",
            "        [ -1.3682,  -3.3282,  -8.6823,  ...,  -4.4666,  -3.3713,  -3.5613],\n",
            "        [ -7.4677,  -3.0070,  -9.7224,  ...,  -4.8216,  -2.7928,  -5.1077]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "\n",
            "Training Loss: 3.070\n",
            "\n",
            " Epoch 2 / 2\n",
            "tensor([[ -7.6663,  -2.7019,  -9.3428,  ...,  -5.0966,  -3.0270,  -5.0057],\n",
            "        [ -9.4556,  -3.3809, -10.2439,  ...,  -6.2978,  -3.3872,  -6.2928],\n",
            "        [ -4.2523,  -3.3842,  -9.1985,  ...,  -4.5965,  -3.1623,  -4.3189],\n",
            "        ...,\n",
            "        [ -6.8878,  -2.4397,  -9.5627,  ...,  -4.7512,  -2.4202,  -4.9929],\n",
            "        [ -7.5366,  -2.5547,  -8.6272,  ...,  -4.9463,  -2.4713,  -5.1339],\n",
            "        [ -6.3884,  -2.6380,  -8.5827,  ...,  -4.5682,  -2.9238,  -4.7359]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.3259,  -2.5933,  -8.6005,  ...,  -5.0804,  -2.9147,  -5.0562],\n",
            "        [-11.1371,  -3.7492, -12.0285,  ...,  -6.7629,  -3.7076,  -7.1101],\n",
            "        [ -9.4716,  -3.1097,  -9.8932,  ...,  -6.0806,  -2.8268,  -6.2367],\n",
            "        ...,\n",
            "        [ -5.2686,  -2.5885,  -6.2945,  ...,  -3.9000,  -2.9149,  -4.0591],\n",
            "        [ -1.3434,  -3.0417,  -7.7230,  ...,  -4.5344,  -2.5066,  -3.5903],\n",
            "        [ -6.8642,  -3.2398,  -8.3095,  ...,  -5.0906,  -3.4867,  -4.8656]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.3181, -2.6312, -7.6167,  ..., -3.6599, -3.3758, -4.2052],\n",
            "        [-3.4404, -3.1181, -6.5875,  ..., -3.5019, -3.1929, -3.6095],\n",
            "        [-2.9378, -3.1086, -6.7666,  ..., -4.1462, -2.9611, -3.5911],\n",
            "        ...,\n",
            "        [-8.2065, -2.9579, -8.4374,  ..., -4.9579, -3.2004, -5.1275],\n",
            "        [-5.8630, -2.4590, -8.0514,  ..., -3.9826, -2.7059, -4.5978],\n",
            "        [-5.9356, -3.0689, -9.0597,  ..., -4.2739, -3.3328, -4.8664]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-10.3835,  -2.8414, -10.3454,  ...,  -6.2736,  -3.5976,  -6.7119],\n",
            "        [ -5.6912,  -2.2321,  -6.5996,  ...,  -3.8554,  -2.7922,  -4.2547],\n",
            "        [ -5.3017,  -2.1651,  -6.4635,  ...,  -4.4619,  -2.2474,  -4.1714],\n",
            "        ...,\n",
            "        [ -9.9163,  -3.2047,  -9.8807,  ...,  -5.4179,  -4.0056,  -6.1211],\n",
            "        [ -8.3826,  -2.8290,  -8.3743,  ...,  -4.8719,  -3.2402,  -5.1960],\n",
            "        [ -4.1248,  -3.2000,  -7.1667,  ...,  -4.2933,  -3.2585,  -4.1103]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.8149, -3.1672, -6.8544,  ..., -3.7032, -3.6263, -4.4510],\n",
            "        [-6.3677, -2.4237, -7.1961,  ..., -3.5140, -3.7762, -4.3530],\n",
            "        [-6.9331, -3.0495, -7.7600,  ..., -3.9949, -3.9252, -4.8627],\n",
            "        ...,\n",
            "        [-8.4224, -2.6455, -8.4640,  ..., -4.9969, -3.8427, -5.6115],\n",
            "        [-8.4465, -2.7898, -8.2213,  ..., -5.1554, -3.3616, -5.6102],\n",
            "        [-5.9745, -2.6760, -7.7150,  ..., -3.8837, -3.0611, -4.6517]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.2363, -2.4273, -7.2604,  ..., -4.6469, -3.0467, -4.9475],\n",
            "        [-5.7019, -2.5365, -6.4417,  ..., -3.7183, -3.6309, -4.4934],\n",
            "        [-7.6319, -2.4486, -7.3156,  ..., -4.3529, -3.5683, -5.0755],\n",
            "        ...,\n",
            "        [-8.0723, -2.6098, -8.4658,  ..., -4.5232, -3.6974, -5.4322],\n",
            "        [-8.5302, -2.5897, -8.1796,  ..., -4.8775, -3.9412, -5.6947],\n",
            "        [-9.6956, -2.7741, -9.0901,  ..., -5.8540, -4.0181, -6.3552]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.9634, -2.8072, -7.4064,  ..., -3.8327, -3.8706, -4.9380],\n",
            "        [-6.9563, -2.4936, -6.5696,  ..., -4.2003, -3.4664, -4.8671],\n",
            "        [-9.7972, -2.9605, -8.7728,  ..., -5.7039, -3.8572, -6.5024],\n",
            "        ...,\n",
            "        [-5.9417, -2.0251, -5.9399,  ..., -4.1486, -2.6633, -4.3582],\n",
            "        [-6.8399, -2.3152, -6.5035,  ..., -4.0326, -3.2718, -4.7201],\n",
            "        [-6.4367, -2.2752, -5.6662,  ..., -3.6911, -3.4089, -4.3934]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.3728, -2.3964, -6.7291,  ..., -3.9716, -3.6810, -5.0095],\n",
            "        [-8.7990, -2.7434, -7.5710,  ..., -5.2400, -3.4484, -5.7858],\n",
            "        [-7.1678, -3.0106, -7.4117,  ..., -3.9145, -3.6875, -5.1453],\n",
            "        ...,\n",
            "        [-5.7485, -2.6675, -5.8333,  ..., -3.5899, -3.6443, -4.4490],\n",
            "        [-4.4825, -2.2168, -5.0763,  ..., -3.1608, -3.1536, -3.8748],\n",
            "        [-6.8992, -2.4728, -6.2110,  ..., -4.1796, -3.0134, -4.9179]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.1263, -3.1595, -5.9633,  ..., -3.6267, -3.4219, -4.3170],\n",
            "        [-3.8841, -2.4533, -4.6124,  ..., -3.5351, -2.6745, -3.6140],\n",
            "        [-7.9320, -2.5569, -6.8629,  ..., -4.6644, -3.7155, -5.3946],\n",
            "        ...,\n",
            "        [-5.1949, -2.6577, -5.0121,  ..., -3.5671, -3.1975, -3.9581],\n",
            "        [-7.0643, -2.3511, -5.9355,  ..., -4.1126, -3.4958, -4.9403],\n",
            "        [-6.6818, -2.3844, -6.0416,  ..., -3.8240, -3.3611, -4.6370]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.3347, -2.4495, -5.2466,  ..., -3.8807, -2.9926, -4.6458],\n",
            "        [-6.4445, -2.4410, -5.5036,  ..., -3.6957, -3.4390, -4.7568],\n",
            "        [-6.3974, -2.4196, -5.5596,  ..., -3.8432, -3.3780, -4.5292],\n",
            "        ...,\n",
            "        [-6.8676, -2.4759, -5.5457,  ..., -4.1114, -3.0257, -4.8907],\n",
            "        [-5.2317, -1.9195, -5.3465,  ..., -3.9971, -2.3042, -4.4015],\n",
            "        [-5.4497, -2.5255, -5.0436,  ..., -3.4663, -2.9900, -4.2121]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.4514, -2.9666, -4.4699,  ..., -3.1833, -3.4736, -3.7929],\n",
            "        [-4.6175, -2.6285, -4.4608,  ..., -3.4958, -2.8581, -3.9580],\n",
            "        [-8.2514, -2.6855, -6.5917,  ..., -4.4099, -3.8719, -5.4500],\n",
            "        ...,\n",
            "        [-7.2728, -2.7123, -6.2607,  ..., -4.8580, -3.4663, -5.3006],\n",
            "        [-5.7454, -2.3196, -4.9866,  ..., -3.5465, -3.4522, -4.4333],\n",
            "        [-5.4987, -2.3176, -4.8692,  ..., -3.9502, -2.9534, -4.3667]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.7171, -2.3506, -4.9445,  ..., -3.7348, -3.4826, -4.3130],\n",
            "        [-5.9142, -2.4316, -4.7844,  ..., -4.0702, -2.9026, -4.5160],\n",
            "        [-3.8558, -2.4792, -4.7282,  ..., -3.3767, -2.9007, -3.8772],\n",
            "        ...,\n",
            "        [-6.3077, -2.3963, -5.1380,  ..., -4.0683, -3.2402, -4.6143],\n",
            "        [-6.5183, -2.4429, -5.4640,  ..., -4.0339, -3.2032, -4.7289],\n",
            "        [-7.9742, -2.7540, -6.3029,  ..., -4.7429, -3.5536, -5.5097]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.7545, -2.4148, -4.9443,  ..., -4.0231, -2.7557, -4.4594],\n",
            "        [-5.7939, -2.3387, -5.0622,  ..., -3.9826, -3.0289, -4.4467],\n",
            "        [-5.4806, -2.3883, -4.7667,  ..., -3.5773, -3.2752, -4.1204],\n",
            "        ...,\n",
            "        [-5.6131, -2.5769, -4.7694,  ..., -4.1049, -3.1434, -4.3637],\n",
            "        [-4.8699, -4.4527, -7.2046,  ..., -4.2640, -4.8853, -4.9545],\n",
            "        [-5.1360, -1.8099, -5.1949,  ..., -4.3490, -2.3292, -4.3303]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.5746, -2.4710, -5.2639,  ..., -4.2129, -3.3947, -4.8483],\n",
            "        [-5.8629, -2.6684, -5.1541,  ..., -4.4890, -2.9966, -4.5483],\n",
            "        [-6.4695, -2.4960, -5.1748,  ..., -4.4406, -3.5939, -4.7467],\n",
            "        ...,\n",
            "        [-6.0518, -2.3652, -5.2338,  ..., -4.4534, -2.8241, -4.7730],\n",
            "        [-4.4027, -2.4992, -4.8281,  ..., -4.1168, -2.5209, -4.0435],\n",
            "        [-5.6020, -2.6106, -5.2213,  ..., -4.4216, -3.1227, -4.5454]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.3244, -2.5886, -5.2351,  ..., -4.4032, -2.7697, -4.4271],\n",
            "        [-2.5451, -2.8228, -5.4610,  ..., -4.4550, -2.1670, -3.8016],\n",
            "        [-3.4209, -2.5206, -4.6491,  ..., -3.4941, -2.4040, -3.6684],\n",
            "        ...,\n",
            "        [-6.2478, -2.3596, -5.0736,  ..., -4.3220, -3.2263, -4.6426],\n",
            "        [-6.3143, -2.5024, -5.3957,  ..., -4.1259, -2.7094, -4.5496],\n",
            "        [-4.9265, -2.1599, -4.4445,  ..., -3.6233, -3.2091, -3.8607]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.2827, -2.4183, -5.6357,  ..., -4.7690, -3.6403, -5.1611],\n",
            "        [-6.2501, -2.2584, -5.4759,  ..., -4.5434, -3.1296, -4.7183],\n",
            "        [-6.2117, -3.2564, -6.2357,  ..., -4.7634, -3.6945, -5.0156],\n",
            "        ...,\n",
            "        [-5.9089, -2.3182, -5.2922,  ..., -4.5617, -2.7285, -4.8289],\n",
            "        [-2.6719, -2.3304, -5.5886,  ..., -4.1651, -2.2492, -3.9862],\n",
            "        [-4.8221, -2.2477, -4.7342,  ..., -4.1502, -2.5428, -4.2618]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.3868, -2.0298, -5.2176,  ..., -4.8104, -3.0855, -4.9792],\n",
            "        [-5.2496, -2.9671, -5.4415,  ..., -4.3541, -2.9679, -4.4813],\n",
            "        [-6.8970, -2.1754, -5.7368,  ..., -4.8265, -3.2995, -5.1691],\n",
            "        ...,\n",
            "        [-7.7360, -2.7458, -6.2504,  ..., -5.3956, -3.3320, -5.7270],\n",
            "        [-6.0882, -2.2242, -5.0419,  ..., -4.2661, -3.4898, -4.6270],\n",
            "        [-5.5240, -1.5068, -6.0908,  ..., -5.1287, -2.1981, -4.9458]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.5232, -2.1397, -5.3699,  ..., -4.4613, -3.3235, -4.9196],\n",
            "        [-3.1334, -3.1487, -6.1974,  ..., -4.0211, -4.0997, -4.2598],\n",
            "        [-5.6919, -2.0636, -5.8075,  ..., -4.8168, -2.5358, -5.2748],\n",
            "        ...,\n",
            "        [-2.2998, -3.4713, -7.5555,  ..., -5.4344, -3.1205, -4.3600],\n",
            "        [-6.0916, -2.1521, -5.7234,  ..., -5.1795, -2.3855, -4.8743],\n",
            "        [-3.6369, -2.4320, -4.7126,  ..., -3.4541, -3.6194, -3.6450]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.7282, -2.6458, -5.6835,  ..., -3.8094, -4.2836, -4.3687],\n",
            "        [-8.3024, -2.9065, -6.5504,  ..., -5.5214, -3.6574, -5.9696],\n",
            "        [-6.3258, -3.5463, -6.6130,  ..., -4.5545, -4.3477, -4.9472],\n",
            "        ...,\n",
            "        [-6.5883, -2.6070, -6.3588,  ..., -5.4243, -3.4371, -5.2964],\n",
            "        [-6.2182, -1.8526, -5.4102,  ..., -4.5359, -3.2749, -4.6797],\n",
            "        [-6.4730, -2.5116, -5.2873,  ..., -4.3578, -3.6127, -4.9421]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-3.3291, -2.2900, -6.7778,  ..., -5.1949, -2.5421, -4.7150],\n",
            "        [-6.2522, -2.1241, -5.5905,  ..., -4.6843, -3.5495, -4.9694],\n",
            "        [-7.2876, -2.4249, -6.5083,  ..., -5.5311, -3.1730, -6.0671],\n",
            "        ...,\n",
            "        [-6.1353, -1.8357, -5.8298,  ..., -4.6380, -3.7685, -5.1647],\n",
            "        [-6.9478, -3.2265, -6.4337,  ..., -4.6258, -4.5491, -5.1638],\n",
            "        [-7.8973, -1.8332, -6.6572,  ..., -5.7982, -3.8651, -6.0258]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -5.4992,  -1.7913,  -5.7400,  ...,  -4.5777,  -3.6293,  -4.6092],\n",
            "        [ -8.3837,  -2.6122,  -6.8537,  ...,  -5.9262,  -4.3313,  -6.4102],\n",
            "        [ -7.9227,  -2.1106,  -6.9272,  ...,  -5.7846,  -3.6413,  -6.1259],\n",
            "        ...,\n",
            "        [ -7.7781,  -1.8626,  -6.9308,  ...,  -5.9385,  -3.6323,  -6.0976],\n",
            "        [ -2.1763,  -2.7131,  -7.8985,  ...,  -4.8134,  -3.9088,  -4.7476],\n",
            "        [ -7.8605,  -5.3302, -10.0892,  ...,  -6.3343,  -7.2713,  -6.8962]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.1440, -2.5492, -7.9323,  ..., -5.6929, -4.5640, -6.5461],\n",
            "        [-5.5523, -1.7223, -5.8606,  ..., -5.2280, -2.3643, -4.9167],\n",
            "        [-7.7927, -2.6144, -6.2192,  ..., -5.7664, -4.2525, -6.0934],\n",
            "        ...,\n",
            "        [-9.8803, -2.8800, -7.5914,  ..., -6.2968, -4.9657, -6.6990],\n",
            "        [-9.3527, -2.4308, -7.8513,  ..., -6.5504, -4.7763, -6.9245],\n",
            "        [-8.6280, -2.0618, -7.2799,  ..., -5.8924, -3.7176, -6.2450]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.2328, -2.3072, -6.6406,  ..., -5.0985, -4.4004, -5.2600],\n",
            "        [-5.2811, -2.7606, -7.0467,  ..., -4.3962, -4.8371, -4.9301],\n",
            "        [-9.2726, -2.8459, -7.7658,  ..., -6.4600, -4.6200, -6.7002],\n",
            "        ...,\n",
            "        [-9.9762, -2.9865, -8.0300,  ..., -6.6911, -4.5756, -7.2442],\n",
            "        [-8.3374, -2.2176, -7.0619,  ..., -5.9808, -3.7189, -6.1764],\n",
            "        [-6.3278, -2.9452, -6.5479,  ..., -4.2153, -5.0844, -4.4860]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.9303,  -2.7699,  -6.5969,  ...,  -5.2868,  -4.0248,  -5.6360],\n",
            "        [ -8.8344,  -2.8630,  -6.9866,  ...,  -5.6059,  -4.2744,  -6.3273],\n",
            "        [ -8.1980,  -2.9316,  -6.6130,  ...,  -5.1661,  -4.3943,  -5.5504],\n",
            "        ...,\n",
            "        [ -8.3928,  -2.4459,  -6.9842,  ...,  -6.3316,  -3.5886,  -6.0463],\n",
            "        [-10.4448,  -3.5054,  -8.2018,  ...,  -7.4066,  -4.6188,  -7.2336],\n",
            "        [ -6.5860,  -2.4760,  -6.9427,  ...,  -4.6953,  -4.2025,  -5.5152]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.3968,  -2.8139,  -7.0109,  ...,  -5.8432,  -4.2326,  -6.2883],\n",
            "        [ -5.7485,  -3.6156,  -7.7412,  ...,  -4.9854,  -5.6927,  -5.2363],\n",
            "        [ -8.4870,  -3.1949,  -8.1116,  ...,  -5.4682,  -4.9069,  -6.1708],\n",
            "        ...,\n",
            "        [-11.0123,  -3.6205,  -8.8941,  ...,  -6.9863,  -4.8189,  -7.3740],\n",
            "        [ -8.9921,  -3.0668,  -7.0510,  ...,  -5.4016,  -4.5036,  -5.9545],\n",
            "        [ -9.0878,  -2.9805,  -7.0598,  ...,  -6.2082,  -4.4792,  -6.1873]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.3544, -2.2327, -6.9245,  ..., -5.9795, -3.5513, -5.9336],\n",
            "        [-6.8703, -2.7548, -5.9279,  ..., -4.9785, -4.0179, -4.8962],\n",
            "        [-5.4372, -1.9256, -6.2576,  ..., -4.6428, -3.3365, -4.5976],\n",
            "        ...,\n",
            "        [-8.4841, -3.2491, -6.6788,  ..., -5.6499, -4.2553, -5.5854],\n",
            "        [-2.2626, -2.2507, -7.2045,  ..., -5.1863, -2.9595, -4.2126],\n",
            "        [-7.0024, -2.5660, -5.7198,  ..., -4.7705, -3.7132, -4.6163]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.4095, -3.2747, -6.3967,  ..., -5.9440, -3.6479, -5.8628],\n",
            "        [-8.1328, -2.7282, -6.6322,  ..., -5.3230, -4.2137, -5.3804],\n",
            "        [-7.7100, -3.1091, -6.8878,  ..., -5.1189, -4.2667, -5.0661],\n",
            "        ...,\n",
            "        [-7.5286, -2.4484, -6.9161,  ..., -5.7615, -2.9632, -5.3129],\n",
            "        [-7.1661, -2.9307, -6.2522,  ..., -4.8618, -4.3144, -4.8936],\n",
            "        [-7.5295, -2.7422, -6.1295,  ..., -4.9590, -4.0942, -4.8268]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.9334, -3.6820, -8.7070,  ..., -6.1290, -4.7371, -6.7359],\n",
            "        [-2.1020, -3.1930, -8.1721,  ..., -5.0749, -3.8617, -4.2824],\n",
            "        [-8.5199, -3.2563, -7.1706,  ..., -5.5695, -3.7600, -5.7133],\n",
            "        ...,\n",
            "        [-7.3269, -2.3879, -6.5048,  ..., -5.3602, -3.0945, -5.4589],\n",
            "        [-4.9697, -1.9927, -6.4581,  ..., -4.4047, -3.9958, -4.3302],\n",
            "        [-7.9120, -2.8667, -6.6346,  ..., -5.2807, -3.7121, -5.3893]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.2505,  -2.1975,  -6.9779,  ...,  -5.8540,  -3.7271,  -5.8623],\n",
            "        [ -7.1442,  -5.4044,  -9.4458,  ...,  -6.0022,  -6.3850,  -5.7951],\n",
            "        [ -8.2287,  -5.9763, -11.3619,  ...,  -7.0966,  -7.5947,  -7.6591],\n",
            "        ...,\n",
            "        [ -8.6199,  -5.2110,  -9.3259,  ...,  -6.1479,  -5.6703,  -5.6321],\n",
            "        [ -7.6041,  -2.8292,  -6.3159,  ...,  -4.8302,  -4.2170,  -4.9118],\n",
            "        [ -9.3465,  -3.0995,  -7.1303,  ...,  -5.8337,  -4.4391,  -6.0024]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-9.7109, -3.4939, -7.4895,  ..., -6.0762, -4.5330, -6.0680],\n",
            "        [-9.4188, -3.2811, -7.3836,  ..., -6.0291, -3.8920, -6.2365],\n",
            "        [-6.9872, -2.5969, -6.2707,  ..., -4.4238, -4.4069, -4.8468],\n",
            "        ...,\n",
            "        [-8.9769, -3.3284, -7.0768,  ..., -5.3675, -4.5523, -5.9531],\n",
            "        [-8.8067, -4.2616, -7.9436,  ..., -5.9380, -4.1385, -5.9430],\n",
            "        [-9.7712, -3.4864, -7.7755,  ..., -6.6207, -4.0694, -6.0127]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -9.1048,  -2.8774,  -7.6603,  ...,  -6.4777,  -2.8050,  -6.1282],\n",
            "        [ -8.3261,  -3.4877,  -6.9830,  ...,  -5.3727,  -3.9779,  -5.1797],\n",
            "        [-12.4689,  -4.7939,  -9.2487,  ...,  -7.8651,  -4.8419,  -7.4693],\n",
            "        ...,\n",
            "        [ -9.1390,  -3.1136,  -7.1783,  ...,  -5.8452,  -4.2262,  -5.3987],\n",
            "        [ -9.1766,  -3.4414,  -6.9703,  ...,  -5.8104,  -3.4342,  -5.8578],\n",
            "        [ -7.6568,  -2.6118,  -6.7223,  ...,  -4.9428,  -4.2624,  -5.3241]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.3448,  -2.2957,  -7.0226,  ...,  -5.2354,  -2.8351,  -5.3155],\n",
            "        [ -8.6374,  -2.8626,  -6.5803,  ...,  -5.8556,  -3.9158,  -5.7111],\n",
            "        [ -8.4430,  -5.2007, -10.6084,  ...,  -6.6590,  -6.5573,  -7.0799],\n",
            "        ...,\n",
            "        [ -7.8675,  -5.6739, -12.6520,  ...,  -7.9090,  -7.3315,  -7.5877],\n",
            "        [ -8.6716,  -2.6504,  -6.8301,  ...,  -5.5178,  -3.5570,  -5.9044],\n",
            "        [ -7.6938,  -4.0585,  -8.5626,  ...,  -5.2302,  -5.2876,  -5.5952]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.0200,  -5.6710, -10.1912,  ...,  -6.9431,  -5.6064,  -5.3281],\n",
            "        [-10.5625,  -3.5266,  -8.3983,  ...,  -6.5524,  -4.3938,  -6.9790],\n",
            "        [ -8.0853,  -2.7295,  -6.2218,  ...,  -4.9690,  -3.8945,  -4.9907],\n",
            "        ...,\n",
            "        [ -9.1464,  -2.6313,  -6.5813,  ...,  -5.6918,  -3.4165,  -5.7343],\n",
            "        [ -6.8107,  -2.6478,  -6.2214,  ...,  -5.1337,  -2.2170,  -4.7402],\n",
            "        [ -6.7849,  -3.8041,  -7.0544,  ...,  -4.9688,  -4.3780,  -4.1424]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.3522, -4.1785, -9.2322,  ..., -5.6973, -4.6975, -5.9909],\n",
            "        [-7.2077, -2.3555, -6.0568,  ..., -5.3359, -2.8662, -4.8722],\n",
            "        [-0.6400, -4.4646, -9.1313,  ..., -6.5136, -2.4407, -4.0803],\n",
            "        ...,\n",
            "        [-7.5428, -3.1428, -6.4982,  ..., -5.2858, -3.0504, -4.4942],\n",
            "        [-7.2227, -2.5468, -6.0220,  ..., -5.1318, -2.1711, -4.7954],\n",
            "        [-9.4679, -3.7891, -6.8227,  ..., -5.9507, -3.0262, -5.7715]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.6956, -3.2936, -6.5257,  ..., -4.4783, -2.9524, -4.3110],\n",
            "        [-8.1193, -2.4083, -6.0417,  ..., -5.4166, -3.6129, -5.4556],\n",
            "        [-7.6160, -2.4758, -5.7443,  ..., -4.6531, -4.0679, -4.6299],\n",
            "        ...,\n",
            "        [-9.9470, -3.0587, -6.8456,  ..., -6.6152, -3.8710, -6.3077],\n",
            "        [-8.4580, -3.0032, -5.9527,  ..., -5.4622, -3.5580, -5.4479],\n",
            "        [-5.6450, -2.0485, -4.9409,  ..., -4.1931, -2.9899, -4.2953]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.3928, -3.2292, -6.6686,  ..., -6.3005, -1.9232, -5.6226],\n",
            "        [-8.4423, -4.4987, -7.6574,  ..., -5.7910, -5.0175, -5.1064],\n",
            "        [-4.6753, -3.6490, -7.0786,  ..., -5.1872, -1.9044, -4.0782],\n",
            "        ...,\n",
            "        [-7.1106, -2.1409, -5.9868,  ..., -5.2095, -2.3996, -5.0321],\n",
            "        [-5.6443, -1.8924, -5.8304,  ..., -4.5543, -2.1403, -4.6373],\n",
            "        [-9.2136, -3.7886, -7.1496,  ..., -6.3658, -3.2904, -5.7483]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.8793, -2.7365, -5.6992,  ..., -5.1895, -2.8589, -4.9872],\n",
            "        [-5.2074, -1.9916, -5.9960,  ..., -5.0427, -1.5596, -4.5859],\n",
            "        [-6.9519, -4.6027, -7.6090,  ..., -5.6046, -4.8554, -4.5340],\n",
            "        ...,\n",
            "        [-4.9264, -2.1994, -6.1631,  ..., -4.4315, -3.6827, -4.6755],\n",
            "        [-9.0998, -3.1300, -6.7247,  ..., -5.6861, -2.9779, -5.5161],\n",
            "        [-6.6863, -1.4695, -7.9617,  ..., -6.1780, -1.4232, -6.2277]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.3404, -2.5916, -7.4798,  ..., -5.9904, -0.6705, -4.3372],\n",
            "        [-4.8698, -2.8888, -5.2746,  ..., -4.1175, -2.5802, -3.5423],\n",
            "        [-8.9321, -2.5052, -6.2790,  ..., -6.2724, -3.0615, -5.7037],\n",
            "        ...,\n",
            "        [-4.4344, -1.8441, -6.4355,  ..., -5.5452, -0.9955, -4.4523],\n",
            "        [-4.8895, -2.6334, -5.8582,  ..., -4.4784, -2.7359, -3.4350],\n",
            "        [-7.4373, -1.9717, -5.4304,  ..., -4.9919, -3.3076, -4.7506]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.8951, -2.9450, -6.3249,  ..., -4.8857, -4.1141, -3.7917],\n",
            "        [-8.4692, -1.7277, -6.3968,  ..., -6.2401, -3.2677, -5.5345],\n",
            "        [-8.8951, -2.9692, -6.2513,  ..., -6.0854, -3.5612, -5.2140],\n",
            "        ...,\n",
            "        [-5.4827, -2.2262, -5.4344,  ..., -4.8954, -1.7109, -4.3470],\n",
            "        [-8.9621, -2.3296, -6.4288,  ..., -6.3246, -3.2187, -5.5917],\n",
            "        [-6.9608, -5.3676, -8.7736,  ..., -6.2968, -4.7805, -4.4320]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -5.3480,  -2.2865,  -5.2388,  ...,  -4.4728,  -2.4324,  -3.8817],\n",
            "        [ -5.1864,  -4.1839,  -8.8022,  ...,  -6.6843,  -3.0712,  -4.3131],\n",
            "        [ -7.6588,  -2.4123,  -5.4631,  ...,  -5.1306,  -3.8602,  -4.5758],\n",
            "        ...,\n",
            "        [-10.7279,  -3.6713,  -7.6700,  ...,  -7.1802,  -4.0667,  -5.9334],\n",
            "        [ -3.7325,  -2.1663,  -5.3187,  ...,  -4.3781,  -2.7207,  -2.8958],\n",
            "        [ -5.9144,  -2.3809,  -5.2563,  ...,  -4.8427,  -2.7181,  -3.7611]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-10.2677,  -4.3423,  -7.2517,  ...,  -6.2575,  -4.4470,  -5.6702],\n",
            "        [ -7.7757,  -2.5130,  -5.9656,  ...,  -5.9775,  -2.6521,  -5.1502],\n",
            "        [ -8.6199,  -3.0181,  -6.2710,  ...,  -5.5621,  -4.3899,  -4.7556],\n",
            "        ...,\n",
            "        [ -8.1350,  -6.5257, -10.0787,  ...,  -7.1622,  -5.3169,  -5.1136],\n",
            "        [ -6.4198,  -2.7494,  -5.9343,  ...,  -4.5856,  -2.9149,  -4.0387],\n",
            "        [ -7.3564,  -3.1540,  -5.6098,  ...,  -5.0857,  -4.0090,  -4.2388]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-10.2170,  -3.5194,  -6.9460,  ...,  -6.5804,  -3.7887,  -5.8091],\n",
            "        [ -8.0961,  -3.1753,  -6.1827,  ...,  -5.3497,  -4.3150,  -4.3269],\n",
            "        [ -7.6455,  -2.3964,  -5.5160,  ...,  -5.0637,  -3.8068,  -4.5428],\n",
            "        ...,\n",
            "        [ -4.6068,  -2.6545,  -7.9339,  ...,  -6.5232,  -0.5708,  -4.5581],\n",
            "        [ -6.8048,  -2.2540,  -5.9992,  ...,  -4.8044,  -4.2902,  -4.0227],\n",
            "        [ -5.1282,  -2.0693,  -6.1133,  ...,  -4.3285,  -3.8961,  -3.6507]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.2734, -3.8575, -6.2019,  ..., -5.0486, -5.0375, -3.9692],\n",
            "        [-7.5919, -3.1664, -5.9034,  ..., -4.9932, -3.4923, -4.2634],\n",
            "        [-8.6800, -3.0641, -6.8817,  ..., -6.4825, -3.5375, -4.9454],\n",
            "        ...,\n",
            "        [-6.9807, -3.1015, -5.6617,  ..., -4.7578, -4.4112, -3.9252],\n",
            "        [-0.6943, -3.3271, -8.5971,  ..., -6.2224, -3.5572, -3.2512],\n",
            "        [-7.1174, -3.2268, -5.5430,  ..., -4.7911, -2.9707, -4.1062]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-11.5170,  -4.2818,  -8.0839,  ...,  -8.0181,  -3.9623,  -6.5086],\n",
            "        [ -8.7480,  -3.4702,  -6.3445,  ...,  -5.6389,  -4.7683,  -4.8810],\n",
            "        [ -8.3949,  -3.3182,  -6.4400,  ...,  -5.6340,  -4.0240,  -4.5598],\n",
            "        ...,\n",
            "        [ -7.0773,  -3.1853,  -6.0577,  ...,  -5.1607,  -3.7901,  -3.8026],\n",
            "        [ -6.5118,  -4.3707,  -7.0693,  ...,  -5.2916,  -5.1842,  -3.6453],\n",
            "        [ -8.0453,  -2.9882,  -5.9429,  ...,  -5.7464,  -3.2658,  -4.6287]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-7.0375, -2.8754, -5.9414,  ..., -5.1512, -3.9757, -3.8510],\n",
            "        [-8.3711, -2.9296, -6.6964,  ..., -6.0892, -3.7736, -4.9364],\n",
            "        [-9.7477, -3.3189, -6.8826,  ..., -6.5293, -5.0601, -5.2520],\n",
            "        ...,\n",
            "        [-7.4896, -3.4864, -7.2495,  ..., -5.3080, -3.8654, -4.7043],\n",
            "        [-7.2804, -1.1303, -6.6823,  ..., -5.7258, -3.0217, -4.0591],\n",
            "        [-9.3573, -3.5908, -7.0354,  ..., -6.3562, -5.5004, -4.9426]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-12.2375,  -4.9751,  -8.6991,  ...,  -8.2846,  -6.0791,  -6.4770],\n",
            "        [ -9.0941,  -2.9400,  -6.8961,  ...,  -6.2226,  -5.2721,  -4.8893],\n",
            "        [ -7.7405,  -2.8706,  -6.4065,  ...,  -5.9546,  -4.4312,  -4.3611],\n",
            "        ...,\n",
            "        [-11.7271,  -4.4486,  -8.3457,  ...,  -7.7462,  -5.9047,  -6.0512],\n",
            "        [ -1.8377,  -3.5171,  -7.6758,  ...,  -5.6030,  -4.1414,  -2.1328],\n",
            "        [ -6.7975,  -5.6771,  -8.8864,  ...,  -6.7095,  -4.7553,  -3.8363]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -9.9539,  -3.5302,  -7.2576,  ...,  -6.6773,  -5.6723,  -4.7642],\n",
            "        [ -9.3785,  -4.0362,  -6.7519,  ...,  -6.1099,  -4.6158,  -4.5858],\n",
            "        [ -9.9675,  -3.5936,  -7.5398,  ...,  -6.5122,  -3.8173,  -5.2935],\n",
            "        ...,\n",
            "        [ -9.9134,  -6.6124, -11.8358,  ...,  -7.6859,  -9.1228,  -5.6975],\n",
            "        [ -7.3726,  -3.4983,  -6.3970,  ...,  -5.1310,  -4.5857,  -3.8299],\n",
            "        [-14.1588,  -4.5691,  -9.7697,  ...,  -9.4811,  -6.6078,  -7.1295]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-10.8232,  -3.0529,  -7.9541,  ...,  -6.9660,  -6.1764,  -5.0782],\n",
            "        [-10.4045,  -4.1837,  -7.3691,  ...,  -6.6213,  -5.2369,  -4.9274],\n",
            "        [-10.6367,  -3.7512,  -7.3104,  ...,  -7.2835,  -5.1218,  -5.3283],\n",
            "        ...,\n",
            "        [-10.1221,  -3.6283,  -7.3249,  ...,  -6.9523,  -4.5346,  -5.0170],\n",
            "        [-11.8131,  -3.9542,  -7.8479,  ...,  -7.7403,  -5.1511,  -6.0055],\n",
            "        [-10.8730,  -3.5177,  -8.4477,  ...,  -6.7024,  -5.8893,  -5.2171]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-10.9916,  -7.9204, -10.8276,  ...,  -7.9128,  -8.1007,  -5.2753],\n",
            "        [-12.8226,  -3.8529,  -9.0113,  ...,  -8.6900,  -5.9199,  -6.4364],\n",
            "        [-11.2898,  -4.4597,  -8.0884,  ...,  -7.5824,  -5.9135,  -5.6379],\n",
            "        ...,\n",
            "        [-10.5206,  -3.1620,  -7.1947,  ...,  -6.6908,  -5.3121,  -5.2579],\n",
            "        [-12.7128,  -4.8700,  -9.0099,  ...,  -7.8210,  -5.9368,  -5.9952],\n",
            "        [ -5.9017,  -2.1625,  -8.7197,  ...,  -7.4461,  -2.2130,  -2.5739]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.9896,  -2.1587,  -6.9423,  ...,  -6.1956,  -3.6359,  -4.1212],\n",
            "        [ -9.7933,  -4.4833,  -9.7544,  ...,  -6.2664,  -7.0355,  -4.5932],\n",
            "        [-10.1895,  -5.5150,  -9.1389,  ...,  -6.5886,  -7.2916,  -4.2993],\n",
            "        ...,\n",
            "        [ -7.6496,  -5.9879,  -9.9304,  ...,  -7.3026,  -6.3515,  -2.9482],\n",
            "        [-11.9066,  -2.8612,  -8.2449,  ...,  -7.1068,  -5.6013,  -5.6925],\n",
            "        [ -8.4228,  -5.2908,  -8.4637,  ...,  -5.6121,  -6.8201,  -3.4364]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -9.2886,  -3.1944,  -6.6687,  ...,  -4.8502,  -4.9433,  -4.1216],\n",
            "        [ -9.1459,  -2.9739,  -6.9115,  ...,  -5.6820,  -4.4404,  -3.8415],\n",
            "        [ -6.1658,  -0.4456,  -8.8643,  ...,  -6.9479,  -3.1744,  -2.8145],\n",
            "        ...,\n",
            "        [-10.9097,  -3.5407,  -7.5321,  ...,  -6.7151,  -5.9016,  -5.2769],\n",
            "        [ -6.4325,  -1.6130,  -6.2080,  ...,  -4.4930,  -3.9459,  -2.6869],\n",
            "        [ -6.3573,  -4.5814,  -7.4022,  ...,  -5.3874,  -4.8772,  -2.6730]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.1805,  -1.4114,  -6.5032,  ...,  -5.5803,  -3.9673,  -3.7632],\n",
            "        [-11.3673,  -3.9167,  -7.7425,  ...,  -6.2032,  -5.0235,  -5.4753],\n",
            "        [ -7.4442,  -2.0637,  -5.9041,  ...,  -4.5256,  -4.4791,  -3.1239],\n",
            "        ...,\n",
            "        [ -9.1179,  -2.8940,  -6.4095,  ...,  -5.0940,  -4.0479,  -4.4209],\n",
            "        [ -8.2318,  -3.0890,  -7.4376,  ...,  -4.7274,  -4.5659,  -3.6263],\n",
            "        [ -5.2271,  -1.8992,  -6.6310,  ...,  -5.1601,  -1.6077,  -2.6347]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.3135, -2.2836, -6.3552,  ..., -4.6877, -4.5415, -3.6648],\n",
            "        [-8.0000, -2.3694, -5.9725,  ..., -4.4539, -4.6228, -3.6603],\n",
            "        [-7.6410, -2.5862, -5.8760,  ..., -4.4657, -3.9046, -3.3007],\n",
            "        ...,\n",
            "        [-9.8305, -3.3059, -7.2657,  ..., -5.9428, -4.5262, -4.8854],\n",
            "        [-9.3828, -2.7764, -6.8959,  ..., -5.5763, -4.8496, -4.7969],\n",
            "        [-6.9668, -1.8460, -5.6134,  ..., -4.1073, -4.6789, -3.4061]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-5.2516, -4.9243, -9.3214,  ..., -5.3931, -5.5478, -2.4687],\n",
            "        [-5.7526, -2.3822, -5.7103,  ..., -3.6530, -4.1728, -2.3402],\n",
            "        [-6.8112, -2.7737, -6.2163,  ..., -4.0591, -5.2863, -2.9847],\n",
            "        ...,\n",
            "        [-6.1952, -3.4610, -6.0298,  ..., -4.1261, -4.5847, -2.8898],\n",
            "        [-9.1972, -3.2615, -7.1796,  ..., -4.9418, -3.8722, -4.8283],\n",
            "        [-7.7341, -2.6088, -5.8118,  ..., -4.4796, -3.8531, -3.8996]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.1624,  -3.1829,  -6.3004,  ...,  -4.7120,  -2.7862,  -3.7963],\n",
            "        [ -5.9003,  -2.7359,  -5.8108,  ...,  -3.9475,  -3.2526,  -2.8943],\n",
            "        [ -8.4511,  -3.0733,  -6.3519,  ...,  -5.2234,  -3.7110,  -4.6017],\n",
            "        ...,\n",
            "        [ -6.8659,  -2.4173,  -6.1547,  ...,  -3.7709,  -4.1702,  -3.2633],\n",
            "        [-12.9550,  -5.4688,  -9.2619,  ...,  -7.3537,  -5.4167,  -6.6589],\n",
            "        [ -3.4926,  -3.8788, -11.1551,  ...,  -8.9327,  -3.2130,  -3.1156]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.9530,  -2.5972,  -5.8905,  ...,  -4.3454,  -2.3018,  -4.0247],\n",
            "        [ -0.7419,  -6.8296, -11.1116,  ...,  -8.3471,  -3.5525,  -1.9196],\n",
            "        [ -5.4593,  -2.8618,  -5.5090,  ...,  -3.6045,  -2.8841,  -3.2406],\n",
            "        ...,\n",
            "        [ -9.0826,  -3.7489,  -7.0339,  ...,  -4.9462,  -3.7559,  -4.8917],\n",
            "        [ -9.2479,  -7.4855, -10.1277,  ...,  -7.1798,  -6.3061,  -5.6368],\n",
            "        [ -4.2836,  -3.3632,  -5.8355,  ...,  -3.7283,  -2.9460,  -2.7823]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -2.6410,  -4.2513,  -8.3903,  ...,  -5.5863,  -3.0628,  -1.8595],\n",
            "        [-10.8214,  -9.3190, -11.9183,  ...,  -7.8768,  -7.4105,  -6.5802],\n",
            "        [ -6.2151,  -2.9620,  -5.4865,  ...,  -4.1301,  -2.3066,  -3.7814],\n",
            "        ...,\n",
            "        [ -5.2788,  -2.9760,  -6.0213,  ...,  -3.5056,  -4.3836,  -3.0391],\n",
            "        [ -6.3673,  -3.4498,  -6.0023,  ...,  -4.1372,  -2.3973,  -3.9393],\n",
            "        [ -9.6851,  -4.0698,  -7.2672,  ...,  -5.2176,  -3.3268,  -5.3316]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-4.5535, -2.4356, -6.6042,  ..., -4.4786, -1.7186, -3.3464],\n",
            "        [-6.5707, -2.8166, -5.5916,  ..., -3.7327, -3.0439, -4.0931],\n",
            "        [-6.3069, -2.0352, -6.0175,  ..., -4.6393, -1.9585, -4.0435],\n",
            "        ...,\n",
            "        [-5.7305, -5.0485, -9.6648,  ..., -5.4752, -6.1435, -3.7370],\n",
            "        [-7.2412, -3.3225, -6.2319,  ..., -3.9866, -3.0130, -4.2651],\n",
            "        [-5.6360, -4.6478, -8.3369,  ..., -4.5116, -3.4521, -3.8531]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -0.0909,  -6.7276, -13.1417,  ...,  -8.4287,  -5.1699,  -3.6844],\n",
            "        [ -5.2383,  -3.8623,  -6.2868,  ...,  -3.1661,  -4.4406,  -3.4762],\n",
            "        [ -6.2982,  -3.1950,  -5.3683,  ...,  -3.5651,  -2.7642,  -4.1618],\n",
            "        ...,\n",
            "        [ -7.7375,  -3.4954,  -6.0382,  ...,  -4.0538,  -3.5777,  -4.8005],\n",
            "        [ -7.9630,  -3.9173,  -6.8623,  ...,  -4.1968,  -3.3464,  -4.8049],\n",
            "        [ -0.3543,  -5.0214,  -9.0085,  ...,  -5.9552,  -4.1748,  -2.2358]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-6.7958, -2.4806, -6.4017,  ..., -4.7252, -1.1195, -4.5223],\n",
            "        [-6.1858, -3.6593, -5.8478,  ..., -3.3327, -2.9372, -4.0377],\n",
            "        [-5.2630, -2.3953, -7.5334,  ..., -4.3861, -1.9240, -4.2509],\n",
            "        ...,\n",
            "        [-7.0701, -3.7546, -5.7908,  ..., -3.9746, -2.7243, -4.6669],\n",
            "        [-4.9291, -3.2058, -5.7959,  ..., -3.7591, -1.3378, -3.8385],\n",
            "        [-5.5437, -3.0535, -5.6561,  ..., -2.7748, -4.0487, -3.7823]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.6779, -4.3686, -6.9702,  ..., -4.2049, -3.5115, -5.6378],\n",
            "        [-3.7649, -3.6231, -6.4985,  ..., -3.6289, -2.2844, -2.8569],\n",
            "        [-9.7298, -3.1440, -8.0088,  ..., -4.6665, -3.9485, -6.3165],\n",
            "        ...,\n",
            "        [-3.6941, -5.9821, -9.9593,  ..., -5.3352, -3.7425, -3.5758],\n",
            "        [-7.5261, -5.9882, -7.7379,  ..., -4.3275, -4.4445, -5.0068],\n",
            "        [-8.2149, -4.4954, -8.9490,  ..., -5.2879, -4.1376, -6.0449]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -5.8301,  -3.3206,  -7.2467,  ...,  -3.3587,  -3.8847,  -4.5897],\n",
            "        [ -5.3825,  -4.5811,  -6.3469,  ...,  -3.8599,  -2.6098,  -4.2774],\n",
            "        [-12.5222,  -4.0106,  -9.1399,  ...,  -5.7567,  -4.6138,  -7.7631],\n",
            "        ...,\n",
            "        [ -6.6557,  -2.7804,  -6.5037,  ...,  -2.9288,  -4.2795,  -4.2852],\n",
            "        [ -9.4183,  -3.2931,  -7.6755,  ...,  -4.9379,  -3.4630,  -6.3452],\n",
            "        [ -5.6620,  -3.5853,  -8.9694,  ...,  -3.7806,  -5.7550,  -4.4427]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.9430, -2.9672, -6.8070,  ..., -4.2451, -3.0222, -6.2017],\n",
            "        [-8.3085, -2.2460, -6.4310,  ..., -3.6753, -3.6287, -5.4239],\n",
            "        [-8.8210, -3.8619, -9.7749,  ..., -4.9753, -5.0535, -6.5684],\n",
            "        ...,\n",
            "        [-7.3597, -2.3974, -6.9242,  ..., -3.5244, -4.0127, -5.1166],\n",
            "        [-6.6223, -3.6574, -7.1117,  ..., -2.9512, -4.1241, -4.2006],\n",
            "        [-8.4994, -2.2913, -6.6694,  ..., -3.7121, -4.7349, -5.2981]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -4.5050,  -4.5315,  -6.6430,  ...,  -3.2627,  -2.2942,  -3.5321],\n",
            "        [-10.7350,  -3.9224,  -8.1304,  ...,  -5.5459,  -4.3687,  -7.1243],\n",
            "        [ -8.7954,  -3.0028,  -6.8585,  ...,  -3.6054,  -4.2307,  -5.8660],\n",
            "        ...,\n",
            "        [ -8.4959,  -4.1294,  -7.4640,  ...,  -3.1300,  -5.1064,  -5.5188],\n",
            "        [ -6.2191,  -2.2931,  -6.9547,  ...,  -4.2882,  -1.1366,  -4.8205],\n",
            "        [ -9.6499,  -3.4614,  -7.1766,  ...,  -4.2416,  -4.8395,  -6.3218]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.3385, -2.5517, -6.5692,  ..., -3.8772, -3.9241, -5.5821],\n",
            "        [-9.2595, -2.9928, -7.7346,  ..., -3.9567, -4.8753, -6.2362],\n",
            "        [-8.7277, -2.6157, -7.0332,  ..., -3.4523, -4.9460, -5.7987],\n",
            "        ...,\n",
            "        [-7.8598, -2.6607, -6.5439,  ..., -3.2083, -5.1070, -5.1523],\n",
            "        [-9.2451, -4.1677, -7.8368,  ..., -3.4513, -5.4543, -5.9354],\n",
            "        [-6.8985, -2.5146, -6.1969,  ..., -2.6483, -5.0422, -4.4117]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -8.5767,  -4.5936,  -7.2269,  ...,  -3.1088,  -4.4870,  -5.5171],\n",
            "        [ -8.4487,  -2.9675,  -6.6950,  ...,  -3.4808,  -4.7689,  -5.5600],\n",
            "        [ -0.1146,  -5.7980, -10.3246,  ...,  -6.4619,  -4.4814,  -3.3387],\n",
            "        ...,\n",
            "        [ -9.1427,  -5.2415,  -9.4996,  ...,  -3.1255,  -6.6064,  -5.6838],\n",
            "        [ -7.0714,  -2.5259,  -7.0830,  ...,  -3.3711,  -3.5482,  -5.0471],\n",
            "        [ -1.4134,  -4.2461,  -7.0247,  ...,  -2.5243,  -4.3646,  -1.9531]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.7890,  -2.7805,  -6.4884,  ...,  -2.7173,  -4.5650,  -5.1067],\n",
            "        [ -9.4830,  -4.0295,  -7.6920,  ...,  -3.9351,  -4.7469,  -6.3958],\n",
            "        [ -7.3850,  -2.4101,  -6.8499,  ...,  -2.7407,  -4.4737,  -4.8194],\n",
            "        ...,\n",
            "        [ -9.1228,  -3.8848,  -7.5821,  ...,  -3.1175,  -4.6221,  -5.5386],\n",
            "        [ -8.0534,  -2.7203,  -6.5212,  ...,  -2.9921,  -4.4045,  -5.3032],\n",
            "        [-12.5555,  -3.2595,  -9.1256,  ...,  -5.6011,  -5.7838,  -8.4970]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-13.0416,  -4.7437, -10.3108,  ...,  -5.0821,  -5.5293,  -8.2695],\n",
            "        [ -7.8960,  -2.5955,  -6.9364,  ...,  -2.4657,  -4.9772,  -5.0288],\n",
            "        [ -8.2838,  -2.8981,  -7.2507,  ...,  -3.2301,  -4.7225,  -5.5347],\n",
            "        ...,\n",
            "        [ -9.2286,  -2.7904,  -7.2195,  ...,  -3.5185,  -4.9734,  -6.0316],\n",
            "        [ -5.7859,  -5.0073,  -6.7877,  ...,  -2.7385,  -4.2412,  -4.1068],\n",
            "        [ -7.0568,  -2.8582,  -6.1645,  ...,  -2.8150,  -3.7548,  -4.6501]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-10.0186,  -2.6474,  -8.3922,  ...,  -3.9337,  -5.0672,  -6.4126],\n",
            "        [ -9.6003,  -2.4798,  -7.8108,  ...,  -4.3287,  -4.5953,  -6.5941],\n",
            "        [ -7.6598,  -2.4425,  -6.6503,  ...,  -2.9330,  -4.2893,  -5.2948],\n",
            "        ...,\n",
            "        [ -8.2407,  -4.1218,  -7.2746,  ...,  -3.1913,  -4.4028,  -5.6118],\n",
            "        [ -7.7473,  -2.1856,  -7.0703,  ...,  -2.4109,  -3.8153,  -5.1316],\n",
            "        [ -9.1010,  -3.0665,  -7.5144,  ...,  -3.5660,  -4.0583,  -6.1327]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -6.6455,  -2.6042,  -6.6183,  ...,  -2.0107,  -5.1334,  -4.4582],\n",
            "        [ -8.3103,  -3.3813,  -7.2516,  ...,  -3.0241,  -3.9971,  -5.5130],\n",
            "        [ -6.6852,  -7.5530,  -9.7086,  ...,  -3.7263,  -5.5403,  -5.2562],\n",
            "        ...,\n",
            "        [-11.4078,  -3.6627,  -9.0606,  ...,  -5.2301,  -4.1488,  -7.7355],\n",
            "        [-10.4933,  -3.3297,  -8.3355,  ...,  -3.7550,  -3.8011,  -6.7387],\n",
            "        [ -7.3316,  -1.9876,  -6.8431,  ...,  -2.3689,  -4.6317,  -5.0478]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.7702,  -2.0866,  -6.6702,  ...,  -3.4670,  -2.4083,  -5.2515],\n",
            "        [ -7.8441,  -1.8510,  -6.9463,  ...,  -3.3507,  -4.2397,  -5.5901],\n",
            "        [ -8.1955,  -2.0170,  -7.2778,  ...,  -2.6676,  -4.7217,  -5.2950],\n",
            "        ...,\n",
            "        [-11.6577,  -3.8425,  -8.7778,  ...,  -4.8903,  -3.9299,  -7.7850],\n",
            "        [-15.1686,  -6.9167, -12.7278,  ...,  -5.8964,  -5.8832,  -9.3958],\n",
            "        [ -4.9058,  -1.6951,  -6.5292,  ...,  -2.2741,  -4.3175,  -3.7780]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.4292, -2.7128, -7.0676,  ..., -3.4346, -2.9300, -5.7009],\n",
            "        [-8.8874, -4.2386, -8.3984,  ..., -2.8464, -5.3648, -5.4738],\n",
            "        [-9.2562, -2.7064, -7.9342,  ..., -4.4825, -3.7315, -6.4192],\n",
            "        ...,\n",
            "        [-5.1697, -1.7501, -7.7826,  ..., -2.5111, -5.3027, -4.4532],\n",
            "        [-6.6068, -4.2159, -7.8383,  ..., -2.2015, -5.1661, -4.4785],\n",
            "        [-9.7238, -1.7008, -8.0749,  ..., -4.6830, -3.9331, -6.8396]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -7.4680,  -1.7600,  -6.9702,  ...,  -3.6880,  -3.1870,  -5.5993],\n",
            "        [ -6.7235,  -5.6427,  -9.2538,  ...,  -3.7266,  -4.2859,  -5.0943],\n",
            "        [ -9.2045,  -2.6047,  -7.8224,  ...,  -3.6829,  -3.7064,  -6.1058],\n",
            "        ...,\n",
            "        [ -8.4258,  -2.6865,  -7.4637,  ...,  -3.7935,  -3.7665,  -5.9277],\n",
            "        [ -5.0839,  -4.4868,  -7.8356,  ...,  -2.1778,  -5.4347,  -3.7512],\n",
            "        [-11.3138,  -3.7489,  -9.7463,  ...,  -4.8178,  -5.3230,  -7.6584]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-12.2841,  -4.5636, -10.0149,  ...,  -5.1227,  -4.3420,  -8.2501],\n",
            "        [ -9.6419,  -7.6473, -10.8509,  ...,  -4.6628,  -4.8370,  -6.8378],\n",
            "        [ -6.5625,  -2.0076,  -6.5782,  ...,  -2.3550,  -4.0645,  -4.5368],\n",
            "        ...,\n",
            "        [ -6.9404,  -2.0993,  -6.9925,  ...,  -3.1326,  -4.4560,  -5.2728],\n",
            "        [ -7.2895,  -1.9199,  -6.5904,  ...,  -3.4289,  -3.5969,  -5.2676],\n",
            "        [ -4.1559,  -1.6360,  -6.8301,  ...,  -3.6828,  -2.4958,  -3.7880]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-8.4031e+00, -3.4237e+00, -8.0113e+00,  ..., -3.6029e+00,\n",
            "         -3.9440e+00, -5.6061e+00],\n",
            "        [-1.1173e-02, -9.9893e+00, -1.6055e+01,  ..., -9.6440e+00,\n",
            "         -7.2228e+00, -5.1954e+00],\n",
            "        [-6.1125e+00, -2.8478e+00, -8.7354e+00,  ..., -3.3418e+00,\n",
            "         -5.5137e+00, -5.0110e+00],\n",
            "        ...,\n",
            "        [-5.5872e+00, -3.9755e+00, -1.1055e+01,  ..., -4.2305e+00,\n",
            "         -6.6430e+00, -4.7663e+00],\n",
            "        [-6.5601e+00, -2.1138e+00, -7.0761e+00,  ..., -2.6401e+00,\n",
            "         -3.2905e+00, -4.6648e+00],\n",
            "        [-7.6566e+00, -2.8834e+00, -7.1771e+00,  ..., -3.3953e+00,\n",
            "         -3.7174e+00, -5.2288e+00]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-9.5454, -2.9935, -9.1891,  ..., -4.4053, -3.4811, -6.4506],\n",
            "        [-5.4177, -4.7494, -9.5312,  ..., -3.4808, -6.5568, -4.7533],\n",
            "        [-8.4245, -2.2387, -7.8437,  ..., -4.6107, -2.3476, -6.2360],\n",
            "        ...,\n",
            "        [-5.8869, -1.7581, -6.8232,  ..., -2.3000, -4.5184, -4.3428],\n",
            "        [-7.2660, -1.8561, -6.5886,  ..., -3.5498, -3.4714, -5.2417],\n",
            "        [-9.0856, -2.1853, -7.6587,  ..., -4.8738, -3.2209, -6.5397]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -4.4095,  -1.6864,  -5.9955,  ...,  -2.9136,  -3.5980,  -3.6935],\n",
            "        [ -6.4769,  -4.2857, -10.5239,  ...,  -3.9115,  -6.9548,  -5.2843],\n",
            "        [ -7.4681,  -1.2396,  -6.7768,  ...,  -3.6631,  -3.0257,  -5.5793],\n",
            "        ...,\n",
            "        [ -6.7822,  -1.4288,  -6.8821,  ...,  -3.3416,  -4.0607,  -5.3376],\n",
            "        [ -7.5931,  -1.5923,  -7.5003,  ...,  -4.3887,  -2.3195,  -5.8516],\n",
            "        [-10.5421,  -1.0419,  -9.5652,  ...,  -6.1906,  -3.1305,  -7.8726]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[ -4.4206,  -2.5839,  -6.4752,  ...,  -3.7850,  -2.2178,  -3.8074],\n",
            "        [ -6.6354,  -2.0151,  -6.4214,  ...,  -3.1307,  -4.3028,  -4.8096],\n",
            "        [-10.2150,  -2.9687,  -7.8543,  ...,  -4.6373,  -3.4227,  -6.8993],\n",
            "        ...,\n",
            "        [ -9.0352,  -1.0021,  -8.4872,  ...,  -5.4153,  -3.3514,  -6.6110],\n",
            "        [ -5.4377,  -2.1785,  -6.0361,  ...,  -2.9541,  -3.3612,  -4.2238],\n",
            "        [ -7.2353,  -1.3550,  -7.2189,  ...,  -4.2524,  -3.0858,  -5.4516]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "\n",
            "Training Loss: 2.146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(str):\n",
        " str = re.sub(r'[^a-zA-Z ]+', '', str)\n",
        " test_text = [str]\n",
        " print(test_text)\n",
        " model.eval()\n",
        " \n",
        " tokens_test_data = tokenizer(\n",
        " test_text,\n",
        " max_length = max_seq_len,\n",
        " pad_to_max_length=True,\n",
        " truncation=True,\n",
        " return_token_type_ids=False\n",
        " )\n",
        " test_seq = torch.tensor(tokens_test_data['input_ids'])\n",
        " test_mask = torch.tensor(tokens_test_data['attention_mask'])\n",
        " \n",
        " preds = None\n",
        " with torch.no_grad():\n",
        "   preds = model(test_seq.to(device), test_mask.to(device))\n",
        " preds = preds.detach().cpu().numpy()\n",
        " preds = np.argmax(preds, axis = 1)\n",
        " print('Intent Identified: ', le.inverse_transform(preds)[0])\n",
        " return le.inverse_transform(preds)[0]\n",
        "def get_response(message): \n",
        "  intent = get_prediction(message)\n",
        "  for i in data['intents']: \n",
        "    \n",
        "    if i[\"tag\"] == intent:\n",
        "      result = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  print(f\"Response : {result}\")\n",
        "  return \"Intent: \"+ intent + '\\n' + \"Response: \" + result\n",
        "      \n"
      ],
      "metadata": {
        "id": "qLMHYizLHc28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out=get_response(' the name of the denver airport')"
      ],
      "metadata": {
        "id": "zferQZQd1fAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a79a38c-23dd-4c62-9ff2-f237e83f0a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' the name of the denver airport']\n",
            "Intent Identified:  atis_airport\n",
            "Response : Dallas/Fort Worth International Airport\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "pTxEWs5Zuhj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d342f920-a0a4-44d2-cb2a-969154fcab48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.8/dist-packages (3.13.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.3)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.8/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.8/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.8/dist-packages (from gradio) (2.1.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.8/dist-packages (from gradio) (0.0.5)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.8/dist-packages (from gradio) (3.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (10.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2022.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from gradio) (0.23.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.8/dist-packages (from gradio) (0.88.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.8/dist-packages (from gradio) (2.12.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.21.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: starlette==0.22.0 in /usr/local/lib/python3.8/dist-packages (from fastapi->gradio) (0.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi->gradio) (4.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi->gradio) (3.6.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->gradio) (1.3.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (0.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.9.24)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.8/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.3)\n",
            "Requirement already satisfied: linkify-it-py~=1.0 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.8/dist-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->gradio) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.6)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.8/dist-packages (from paramiko->gradio) (38.0.4)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from paramiko->gradio) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.8/dist-packages (from paramiko->gradio) (4.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "_Q_ZJtCxLZCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo=gr.Interface(fn=get_response,\n",
        "             inputs=['text'],\n",
        "             outputs=['text'])"
      ],
      "metadata": {
        "id": "felZUW4jLcjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch()"
      ],
      "metadata": {
        "id": "n6-TjBvGRvP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "268a5d31-b520-4097-ef30-162eb5731e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7864, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    }
  ]
}